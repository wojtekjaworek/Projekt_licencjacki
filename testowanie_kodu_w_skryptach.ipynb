{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tda_models import TDA_PI34_Model, TDA_PI42_Model, VECTOR_STITCHING_PI_Model_34, VECTOR_STITCHING_PI_Model_42\n",
    "from models.raw_models import Raw_Model, Dummy_Model\n",
    "from tda_pipelines import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch dataset, prepare training and testing sets, generate distorted sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (70000, 784), y shape: (70000,)\n",
      "X_train shape: (1000, 28, 28), y_train shape: (1000,)\n",
      "X_test shape: (300, 28, 28), y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# fetch data, prepare for pipeline and test models\n",
    "\n",
    "from sklearn.datasets import fetch_openml \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "train_size, test_size = 1000, 300 # Reshape to (n_samples, n_pixels_x, n_pixels_y) \n",
    "X = X.reshape((-1, 28, 28)) \n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, train_size=train_size, test_size=test_size, stratify=y, random_state=666 ) \n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\") \n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "# mnist comes with string labels, we need to convert them to int\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Noisy Image with Random Noise')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distort X_train and X_test a little bit not using giotto\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from skimage.util import random_noise\n",
    "X_train_noisy = random_noise(X_train, mode=\"s&p\",amount=0.05, seed=666)\n",
    "X_test_noisy = random_noise(X_test, mode=\"s&p\",amount=0.05, seed=666)\n",
    "\n",
    "# generate random noise matrix of size X_train_noisy.shape and X_test_noisy.shape but without original image\n",
    "\n",
    "X_train_noisy_random = np.random.rand(*X_train_noisy.shape)\n",
    "X_test_noisy_random = np.random.rand(*X_test_noisy.shape)\n",
    "\n",
    "# for each image in X_train_noisy and X_test_noisy, we will add the random noise matrix to the image\n",
    "\n",
    "X_train_noisy_random = X_train_noisy + X_train_noisy_random\n",
    "X_test_noisy_random = X_test_noisy + 0.5*X_test_noisy_random\n",
    "\n",
    "# plot the original image, the noisy image and the noisy image with random noise\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(X_test[5], cmap=\"gray\")\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[1].imshow(X_test_noisy[5], cmap=\"gray\")\n",
    "ax[1].set_title(\"Noisy Image\")\n",
    "ax[2].imshow(X_test_noisy_random[5], cmap=\"gray\")\n",
    "ax[2].set_title(\"Noisy Image with Random Noise\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TDA and Vector-stitching pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipelines \n",
    "\n",
    "tda_pipeline_34 = TDA_PI34_Pipeline()\n",
    "tda_pipeline_42 = TDA_PI42_Pipeline()\n",
    "vector_stitching_pipeline_34, tda_union_34 = VECTOR_STITCHING_PI_Pipeline_34()\n",
    "vector_stitching_pipeline_42, tda_union_42 = VECTOR_STITCHING_PI_Pipeline_42()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform raw data to persistance images and stitched RAW-PI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "\n",
    "X_train_clean_tda_34 = tda_pipeline_34.fit_transform(X_train)\n",
    "X_test_clean_tda_34 = tda_pipeline_34.transform(X_test)\n",
    "X_train_clean_tda_42 = tda_pipeline_42.fit_transform(X_train)\n",
    "X_test_clean_tda_42 = tda_pipeline_42.transform(X_test)\n",
    "\n",
    "# distorted data\n",
    "X_train_noisy_tda_34 = tda_pipeline_34.fit_transform(X_train_noisy_random)\n",
    "X_test_noisy_tda_34 = tda_pipeline_34.transform(X_test_noisy_random)\n",
    "X_train_noisy_tda_42 = tda_pipeline_42.fit_transform(X_train_noisy_random)\n",
    "X_test_noisy_tda_42 = tda_pipeline_42.transform(X_test_noisy_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#important for initializing Binarizer\n",
    "#X_training = tda_union.fit(X_train)\n",
    "\n",
    "#clean data\n",
    "X_train_clean_vector_stitching_34 = vector_stitching_pipeline_34.fit_transform(X_train)\n",
    "X_test_clean_vector_stitching_34 = vector_stitching_pipeline_34.transform(X_test)\n",
    "X_train_clean_vector_stitching_42 = vector_stitching_pipeline_42.fit_transform(X_train)\n",
    "X_test_clean_vector_stitching_42 = vector_stitching_pipeline_42.transform(X_test)\n",
    "\n",
    "# distorted data\n",
    "X_train_noisy_vector_stitching_34 = vector_stitching_pipeline_34.fit_transform(X_train_noisy_random)\n",
    "X_test_noisy_vector_stitching_34 = vector_stitching_pipeline_34.transform(X_test_noisy_random)\n",
    "X_train_noisy_vector_stitching_42 = vector_stitching_pipeline_42.fit_transform(X_train_noisy_random)\n",
    "X_test_noisy_vector_stitching_42 = vector_stitching_pipeline_42.transform(X_test_noisy_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean_tda_good shape: (1000, 28, 28, 34), X_test_clean_tda_good shape: (300, 28, 28, 34)\n",
      "X_train_noisy_tda_good shape: (1000, 28, 28, 34), X_test_noisy_tda_good shape: (300, 28, 28, 34)\n",
      "X_train_clean_vector_stitching_good shape: (1000, 56, 28, 34), X_test_clean_vector_stitching_good shape: (300, 56, 28, 34)\n",
      "X_train_noisy_vector_stitching_good shape: (1000, 56, 28, 34), X_test_noisy_vector_stitching_good shape: (300, 56, 28, 34)\n",
      "X_train_clean_tda_good shape: (1000, 28, 28, 42), X_test_clean_tda_good shape: (300, 28, 28, 42)\n",
      "X_train_noisy_tda_good shape: (1000, 28, 28, 42), X_test_noisy_tda_good shape: (300, 28, 28, 42)\n",
      "X_train_clean_vector_stitching_good shape: (1000, 56, 28, 42), X_test_clean_vector_stitching_good shape: (300, 56, 28, 42)\n",
      "X_train_noisy_vector_stitching_good shape: (1000, 56, 28, 42), X_test_noisy_vector_stitching_good shape: (300, 56, 28, 42)\n"
     ]
    }
   ],
   "source": [
    "# this needs to be integrated into pipeline, transposing the data to fit the input shape of the model\n",
    "\n",
    "# normal tda\n",
    "X_train_clean_tda_good_34 = np.transpose(X_train_clean_tda_34, (0, 3, 2, 1))\n",
    "X_test_clean_tda_good_34 = np.transpose(X_test_clean_tda_34, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_tda_good_34 = np.transpose(X_train_noisy_tda_34, (0, 3, 2, 1))\n",
    "X_test_noisy_tda_good_34 = np.transpose(X_test_noisy_tda_34, (0, 3, 2, 1))\n",
    "\n",
    "X_train_clean_tda_good_42 = np.transpose(X_train_clean_tda_42, (0, 3, 2, 1))\n",
    "X_test_clean_tda_good_42 = np.transpose(X_test_clean_tda_42, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_tda_good_42 = np.transpose(X_train_noisy_tda_42, (0, 3, 2, 1))\n",
    "X_test_noisy_tda_good_42 = np.transpose(X_test_noisy_tda_42, (0, 3, 2, 1))\n",
    "\n",
    "#stitched\n",
    "\n",
    "X_train_clean_vector_stitching_good_34 = np.transpose(X_train_clean_vector_stitching_34, (0, 3, 2, 1))\n",
    "X_test_clean_vector_stitching_good_34 = np.transpose(X_test_clean_vector_stitching_34, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_vector_stitching_good_34 = np.transpose(X_train_noisy_vector_stitching_34, (0, 3, 2, 1))\n",
    "X_test_noisy_vector_stitching_good_34 = np.transpose(X_test_noisy_vector_stitching_34, (0, 3, 2, 1))\n",
    "\n",
    "X_train_clean_vector_stitching_good_42 = np.transpose(X_train_clean_vector_stitching_42, (0, 3, 2, 1))\n",
    "X_test_clean_vector_stitching_good_42 = np.transpose(X_test_clean_vector_stitching_42, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_vector_stitching_good_42 = np.transpose(X_train_noisy_vector_stitching_42, (0, 3, 2, 1))\n",
    "X_test_noisy_vector_stitching_good_42 = np.transpose(X_test_noisy_vector_stitching_42, (0, 3, 2, 1))\n",
    "\n",
    "# shapes\n",
    "print(f\"X_train_clean_tda_good shape: {X_train_clean_tda_good_34.shape}, X_test_clean_tda_good shape: {X_test_clean_tda_good_34.shape}\")\n",
    "print(f\"X_train_noisy_tda_good shape: {X_train_noisy_tda_good_34.shape}, X_test_noisy_tda_good shape: {X_test_noisy_tda_good_34.shape}\")\n",
    "print(f\"X_train_clean_vector_stitching_good shape: {X_train_clean_vector_stitching_good_34.shape}, X_test_clean_vector_stitching_good shape: {X_test_clean_vector_stitching_good_34.shape}\")\n",
    "print(f\"X_train_noisy_vector_stitching_good shape: {X_train_noisy_vector_stitching_good_34.shape}, X_test_noisy_vector_stitching_good shape: {X_test_noisy_vector_stitching_good_34.shape}\")\n",
    "\n",
    "print(f\"X_train_clean_tda_good shape: {X_train_clean_tda_good_42.shape}, X_test_clean_tda_good shape: {X_test_clean_tda_good_42.shape}\")\n",
    "print(f\"X_train_noisy_tda_good shape: {X_train_noisy_tda_good_42.shape}, X_test_noisy_tda_good shape: {X_test_noisy_tda_good_42.shape}\")\n",
    "print(f\"X_train_clean_vector_stitching_good shape: {X_train_clean_vector_stitching_good_42.shape}, X_test_clean_vector_stitching_good shape: {X_test_clean_vector_stitching_good_42.shape}\")\n",
    "print(f\"X_train_noisy_vector_stitching_good shape: {X_train_noisy_vector_stitching_good_42.shape}, X_test_noisy_vector_stitching_good shape: {X_test_noisy_vector_stitching_good_42.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_expanded, X_test_noisy_random_expanded, X_test_expanded = transform_data(X_train, X_test_noisy_random, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "raw_model = Raw_Model() # cnn models working on raw images\n",
    "dummy_model = Dummy_Model() # fully dense model working on raw images\n",
    "tda_model_34 = TDA_PI34_Model() # cnn model working on persistance images\n",
    "tda_model_42 = TDA_PI42_Model() # cnn model working on persistance images\n",
    "vector_stitching_model_34 = VECTOR_STITCHING_PI_Model_34() # cnn model working on stitched raw and PI images\n",
    "vector_stitching_model_42 = VECTOR_STITCHING_PI_Model_42() # cnn model working on stitched raw and PI images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and validating models\n",
    "\n",
    "All models are trained on clean data, and then validated on only distorted data (look up 2nd paragraph to see plotted example images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.3590 - accuracy: 0.5760 - val_loss: 0.6357 - val_accuracy: 0.8067\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.6317 - accuracy: 0.8300 - val_loss: 0.5694 - val_accuracy: 0.8400\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.4016 - accuracy: 0.8960 - val_loss: 0.2759 - val_accuracy: 0.9167\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.2982 - accuracy: 0.9190 - val_loss: 0.3462 - val_accuracy: 0.9033\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.2378 - accuracy: 0.9290 - val_loss: 0.3213 - val_accuracy: 0.8967\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.2453 - accuracy: 0.9250 - val_loss: 0.6148 - val_accuracy: 0.8567\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1777 - accuracy: 0.9460 - val_loss: 0.3498 - val_accuracy: 0.9133\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1661 - accuracy: 0.9470 - val_loss: 0.4376 - val_accuracy: 0.8800\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1227 - accuracy: 0.9630 - val_loss: 0.3790 - val_accuracy: 0.8967\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0977 - accuracy: 0.9750 - val_loss: 0.4798 - val_accuracy: 0.8867\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1116 - accuracy: 0.9630 - val_loss: 0.3832 - val_accuracy: 0.8967\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0731 - accuracy: 0.9780 - val_loss: 0.2891 - val_accuracy: 0.9167\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0722 - accuracy: 0.9770 - val_loss: 0.5324 - val_accuracy: 0.8767\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1377 - accuracy: 0.9540 - val_loss: 0.5171 - val_accuracy: 0.8967\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0738 - accuracy: 0.9830 - val_loss: 0.5006 - val_accuracy: 0.9067\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0645 - accuracy: 0.9820 - val_loss: 0.4361 - val_accuracy: 0.9133\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0688 - accuracy: 0.9820 - val_loss: 0.3752 - val_accuracy: 0.9200\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0688 - accuracy: 0.9820 - val_loss: 0.5413 - val_accuracy: 0.9100\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0468 - accuracy: 0.9840 - val_loss: 0.3995 - val_accuracy: 0.9133\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0172 - accuracy: 0.9920 - val_loss: 0.4427 - val_accuracy: 0.9067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x237149485b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TDA model\n",
    "\n",
    "tda_model_34.model.fit(X_train_clean_tda_good_34, y_train, epochs=20, batch_size=10, validation_data=(X_test_clean_tda_good_34, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.7118 - accuracy: 0.4090 - val_loss: 1.1040 - val_accuracy: 0.7167\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.8115 - accuracy: 0.7710 - val_loss: 0.5205 - val_accuracy: 0.8367\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.5121 - accuracy: 0.8390 - val_loss: 0.4020 - val_accuracy: 0.8767\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.4201 - accuracy: 0.8760 - val_loss: 0.4280 - val_accuracy: 0.8767\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.3048 - accuracy: 0.9070 - val_loss: 0.3767 - val_accuracy: 0.8933\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.3441 - accuracy: 0.8900 - val_loss: 0.3528 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2207 - accuracy: 0.9380 - val_loss: 0.4439 - val_accuracy: 0.8867\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1898 - accuracy: 0.9380 - val_loss: 0.4375 - val_accuracy: 0.8933\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1504 - accuracy: 0.9550 - val_loss: 0.4543 - val_accuracy: 0.9133\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1891 - accuracy: 0.9460 - val_loss: 0.3268 - val_accuracy: 0.9300\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1180 - accuracy: 0.9570 - val_loss: 0.3838 - val_accuracy: 0.9267\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1214 - accuracy: 0.9600 - val_loss: 0.4529 - val_accuracy: 0.9133\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0903 - accuracy: 0.9770 - val_loss: 0.4278 - val_accuracy: 0.9267\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0501 - accuracy: 0.9810 - val_loss: 0.6932 - val_accuracy: 0.8800\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0889 - accuracy: 0.9740 - val_loss: 0.5288 - val_accuracy: 0.9167\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1454 - accuracy: 0.9570 - val_loss: 0.4468 - val_accuracy: 0.9133\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0893 - accuracy: 0.9720 - val_loss: 0.4982 - val_accuracy: 0.9033\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1807 - accuracy: 0.9520 - val_loss: 0.3982 - val_accuracy: 0.9200\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0487 - accuracy: 0.9840 - val_loss: 0.3842 - val_accuracy: 0.9333\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.0341 - accuracy: 0.9850 - val_loss: 0.4485 - val_accuracy: 0.9133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2371450ae50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tda_model_42.model.fit(X_train_clean_tda_good_42, y_train, epochs=20, batch_size=10, validation_data=(X_test_clean_tda_good_42, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 3.0239 - accuracy: 0.4770 - val_loss: 2.2938 - val_accuracy: 0.1667\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.8070 - val_loss: 2.2915 - val_accuracy: 0.1600\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8970 - val_loss: 2.2878 - val_accuracy: 0.1767\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.2837 - accuracy: 0.9120 - val_loss: 2.2881 - val_accuracy: 0.1367\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.1453 - accuracy: 0.9540 - val_loss: 2.2798 - val_accuracy: 0.1467\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9590 - val_loss: 2.2829 - val_accuracy: 0.1867\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.1094 - accuracy: 0.9640 - val_loss: 2.2800 - val_accuracy: 0.1667\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0916 - accuracy: 0.9770 - val_loss: 2.2791 - val_accuracy: 0.1833\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9870 - val_loss: 2.2755 - val_accuracy: 0.2500\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0482 - accuracy: 0.9800 - val_loss: 2.2747 - val_accuracy: 0.1767\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9880 - val_loss: 2.2743 - val_accuracy: 0.2433\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9720 - val_loss: 2.2760 - val_accuracy: 0.1567\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9650 - val_loss: 2.2833 - val_accuracy: 0.1567\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0317 - accuracy: 0.9900 - val_loss: 2.2756 - val_accuracy: 0.1667\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9850 - val_loss: 2.2738 - val_accuracy: 0.1533\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0345 - accuracy: 0.9860 - val_loss: 2.2753 - val_accuracy: 0.1933\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0808 - accuracy: 0.9800 - val_loss: 2.2792 - val_accuracy: 0.1800\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0355 - accuracy: 0.9900 - val_loss: 2.2757 - val_accuracy: 0.1900\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9860 - val_loss: 2.2738 - val_accuracy: 0.1800\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0839 - accuracy: 0.9830 - val_loss: 2.2796 - val_accuracy: 0.1167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2371e383220>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAW model\n",
    "raw_model.model.fit(X_train_expanded, y_train, epochs=20, batch_size=10, validation_data=(X_test_noisy_random_expanded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 1.1516 - accuracy: 0.6210 - val_loss: 0.2813 - val_accuracy: 0.9167\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.3936 - accuracy: 0.8760 - val_loss: 0.1918 - val_accuracy: 0.9400\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.2810 - accuracy: 0.9200 - val_loss: 0.1507 - val_accuracy: 0.9467\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.2057 - accuracy: 0.9360 - val_loss: 0.1991 - val_accuracy: 0.9433\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.1976 - accuracy: 0.9310 - val_loss: 0.1460 - val_accuracy: 0.9400\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.1312 - accuracy: 0.9510 - val_loss: 0.1071 - val_accuracy: 0.9667\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.1108 - accuracy: 0.9620 - val_loss: 0.1224 - val_accuracy: 0.9633\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0724 - accuracy: 0.9740 - val_loss: 0.1359 - val_accuracy: 0.9767\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0548 - accuracy: 0.9840 - val_loss: 0.2145 - val_accuracy: 0.9433\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0755 - accuracy: 0.9740 - val_loss: 0.1093 - val_accuracy: 0.9600\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0562 - accuracy: 0.9850 - val_loss: 0.1456 - val_accuracy: 0.9567\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0404 - accuracy: 0.9890 - val_loss: 0.1760 - val_accuracy: 0.9633\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0805 - accuracy: 0.9740 - val_loss: 0.1756 - val_accuracy: 0.9667\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.0952 - val_accuracy: 0.9733\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0404 - accuracy: 0.9890 - val_loss: 0.1510 - val_accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0243 - accuracy: 0.9890 - val_loss: 0.1618 - val_accuracy: 0.9567\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 0.1592 - val_accuracy: 0.9667\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0432 - accuracy: 0.9810 - val_loss: 0.2892 - val_accuracy: 0.9500\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0750 - accuracy: 0.9790 - val_loss: 0.1438 - val_accuracy: 0.9700\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 1s 14ms/step - loss: 0.0342 - accuracy: 0.9870 - val_loss: 0.1214 - val_accuracy: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2371491e8b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector stitching model\n",
    "\n",
    "vector_stitching_model_34.model.fit(X_train_clean_vector_stitching_good_34, y_train, epochs=20, batch_size=10, validation_data=(X_test_clean_vector_stitching_good_34, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.3208 - accuracy: 0.5570 - val_loss: 0.4790 - val_accuracy: 0.8467\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.4551 - accuracy: 0.8560 - val_loss: 0.2881 - val_accuracy: 0.9167\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.2970 - accuracy: 0.9110 - val_loss: 0.3411 - val_accuracy: 0.8867\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1845 - accuracy: 0.9460 - val_loss: 0.1207 - val_accuracy: 0.9600\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.1589 - accuracy: 0.9470 - val_loss: 0.1826 - val_accuracy: 0.9467\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1117 - accuracy: 0.9630 - val_loss: 0.2451 - val_accuracy: 0.9467\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.1209 - accuracy: 0.9620 - val_loss: 0.1546 - val_accuracy: 0.9467\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0781 - accuracy: 0.9740 - val_loss: 0.1867 - val_accuracy: 0.9467\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0759 - accuracy: 0.9770 - val_loss: 0.0803 - val_accuracy: 0.9800\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0398 - accuracy: 0.9890 - val_loss: 0.1043 - val_accuracy: 0.9733\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0751 - accuracy: 0.9740 - val_loss: 0.1881 - val_accuracy: 0.9533\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0675 - accuracy: 0.9790 - val_loss: 0.2048 - val_accuracy: 0.9567\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0781 - accuracy: 0.9760 - val_loss: 0.1472 - val_accuracy: 0.9533\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0492 - accuracy: 0.9840 - val_loss: 0.1245 - val_accuracy: 0.9700\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.1822 - val_accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 0.1383 - val_accuracy: 0.9667\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.1340 - val_accuracy: 0.9700\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.1606 - val_accuracy: 0.9600\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.0397 - accuracy: 0.9880 - val_loss: 0.2118 - val_accuracy: 0.9600\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.0149 - accuracy: 0.9970 - val_loss: 0.1834 - val_accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x237180a2e80>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_stitching_model_42.model.fit(X_train_clean_vector_stitching_good_42, y_train, epochs=20, batch_size=10, validation_data=(X_test_clean_vector_stitching_good_42, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
