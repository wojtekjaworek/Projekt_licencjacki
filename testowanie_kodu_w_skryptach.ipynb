{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jawor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.tda_models import TDA_PI34_Model, TDA_PI42_Model, VECTOR_STITCHING_PI_Model_34, VECTOR_STITCHING_PI_Model_42\n",
    "from models.raw_models import Raw_Model, Dummy_Model\n",
    "from tda_pipelines import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch dataset, prepare training and testing sets, generate distorted sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (60000, 28, 28), y shape: (60000,)\n",
      "X_train shape: (100, 28, 28), y_train shape: (100,)\n",
      "X_test shape: (100, 28, 28), y_test shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "# fetch data, prepare for pipeline and test models\n",
    "\n",
    "from sklearn.datasets import fetch_openml \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "#X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "\n",
    "(X, y), _ = tf.keras.datasets.mnist.load_data()\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "train_size, test_size = 100, 100 # Reshape to (n_samples, n_pixels_x, n_pixels_y) \n",
    "X = X.reshape((-1, 28, 28)) \n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, train_size=train_size, test_size=test_size, stratify=y, random_state=666 ) \n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\") \n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "# mnist comes with string labels, we need to convert them to int\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jawor\\AppData\\Local\\Temp\\ipykernel_30508\\2546615655.py:5: FutureWarning: `seed` is a deprecated argument name for `random_noise`. It will be removed in version 0.23. Please use `rng` instead.\n",
      "  X_train_noisy = random_noise(X_train, mode=\"s&p\",amount=0.05, seed=666)\n",
      "C:\\Users\\jawor\\AppData\\Local\\Temp\\ipykernel_30508\\2546615655.py:6: FutureWarning: `seed` is a deprecated argument name for `random_noise`. It will be removed in version 0.23. Please use `rng` instead.\n",
      "  X_test_noisy = random_noise(X_test, mode=\"s&p\",amount=0.05, seed=666)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Noisy Image with Random Noise')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distort X_train and X_test a little bit not using giotto\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from skimage.util import random_noise\n",
    "X_train_noisy = random_noise(X_train, mode=\"s&p\",amount=0.05, seed=666)\n",
    "X_test_noisy = random_noise(X_test, mode=\"s&p\",amount=0.05, seed=666)\n",
    "\n",
    "# generate random noise matrix of size X_train_noisy.shape and X_test_noisy.shape but without original image\n",
    "\n",
    "X_train_gaussian_noise = np.random.rand(*X_train_noisy.shape)\n",
    "X_test_gaussian_noise = np.random.rand(*X_test_noisy.shape)\n",
    "\n",
    "# for each image in X_train_noisy and X_test_noisy, we will add the random noise matrix to the image\n",
    "\n",
    "X_train_noisy_random = X_train_noisy + X_train_gaussian_noise\n",
    "X_test_noisy_random = X_test_noisy + 0.5*X_test_gaussian_noise\n",
    "\n",
    "# plot the original image, the noisy image and the noisy image with random noise\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(X_test[5], cmap=\"gray\")\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[1].imshow(X_test_noisy[5], cmap=\"gray\")\n",
    "ax[1].set_title(\"Noisy Image\")\n",
    "ax[2].imshow(X_test_noisy_random[5], cmap=\"gray\")\n",
    "ax[2].set_title(\"Noisy Image with Random Noise\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TDA and Vector-stitching pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipelines \n",
    "\n",
    "tda_pipeline_34 = TDA_PI34_Pipeline()\n",
    "tda_pipeline_42 = TDA_PI42_Pipeline()\n",
    "vector_stitching_pipeline_34, tda_union_34 = VECTOR_STITCHING_PI_Pipeline_34()\n",
    "vector_stitching_pipeline_42, tda_union_42 = VECTOR_STITCHING_PI_Pipeline_42()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform raw data to persistance images and stitched RAW-PI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# clean data\n",
    "\n",
    "X_train_clean_tda_34 = tda_pipeline_34.fit_transform(X_train)\n",
    "print(\"done\")\n",
    "X_test_clean_tda_34 = tda_pipeline_34.transform(X_test)\n",
    "print(\"done\")\n",
    "\n",
    "# distorted data\n",
    "X_train_noisy_tda_34 = tda_pipeline_34.fit_transform(X_train_noisy_random)\n",
    "print(\"done\")\n",
    "X_test_noisy_tda_34 = tda_pipeline_34.transform(X_test_noisy_random)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#important for initializing Binarizer\n",
    "#X_training = tda_union.fit(X_train)\n",
    "\n",
    "#clean data\n",
    "X_train_clean_vector_stitching_34 = vector_stitching_pipeline_34.fit_transform(X_train)\n",
    "print(\"done\")\n",
    "X_test_clean_vector_stitching_34 = vector_stitching_pipeline_34.transform(X_test)\n",
    "print(\"done\")\n",
    "\n",
    "# distorted data\n",
    "X_train_noisy_vector_stitching_34 = vector_stitching_pipeline_34.fit_transform(X_train_noisy_random)\n",
    "print(\"done\")\n",
    "X_test_noisy_vector_stitching_34 = vector_stitching_pipeline_34.transform(X_test_noisy_random)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean_tda_good shape: (100, 28, 28, 34), X_test_clean_tda_good shape: (100, 28, 28, 34)\n",
      "X_train_noisy_tda_good shape: (100, 28, 28, 34), X_test_noisy_tda_good shape: (100, 28, 28, 34)\n",
      "X_train_clean_vector_stitching_good shape: (100, 56, 28, 34), X_test_clean_vector_stitching_good shape: (100, 56, 28, 34)\n",
      "X_train_noisy_vector_stitching_good shape: (100, 56, 28, 34), X_test_noisy_vector_stitching_good shape: (100, 56, 28, 34)\n"
     ]
    }
   ],
   "source": [
    "# this needs to be integrated into pipeline, transposing the data to fit the input shape of the model\n",
    "\n",
    "# normal tda\n",
    "X_train_clean_tda_good_34 = np.transpose(X_train_clean_tda_34, (0, 3, 2, 1))\n",
    "X_test_clean_tda_good_34 = np.transpose(X_test_clean_tda_34, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_tda_good_34 = np.transpose(X_train_noisy_tda_34, (0, 3, 2, 1))\n",
    "X_test_noisy_tda_good_34 = np.transpose(X_test_noisy_tda_34, (0, 3, 2, 1))\n",
    "\n",
    "#stitched\n",
    "\n",
    "X_train_clean_vector_stitching_good_34 = np.transpose(X_train_clean_vector_stitching_34, (0, 3, 2, 1))\n",
    "X_test_clean_vector_stitching_good_34 = np.transpose(X_test_clean_vector_stitching_34, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_vector_stitching_good_34 = np.transpose(X_train_noisy_vector_stitching_34, (0, 3, 2, 1))\n",
    "X_test_noisy_vector_stitching_good_34 = np.transpose(X_test_noisy_vector_stitching_34, (0, 3, 2, 1))\n",
    "\n",
    "# shapes\n",
    "print(f\"X_train_clean_tda_good shape: {X_train_clean_tda_good_34.shape}, X_test_clean_tda_good shape: {X_test_clean_tda_good_34.shape}\")\n",
    "print(f\"X_train_noisy_tda_good shape: {X_train_noisy_tda_good_34.shape}, X_test_noisy_tda_good shape: {X_test_noisy_tda_good_34.shape}\")\n",
    "print(f\"X_train_clean_vector_stitching_good shape: {X_train_clean_vector_stitching_good_34.shape}, X_test_clean_vector_stitching_good shape: {X_test_clean_vector_stitching_good_34.shape}\")\n",
    "print(f\"X_train_noisy_vector_stitching_good shape: {X_train_noisy_vector_stitching_good_34.shape}, X_test_noisy_vector_stitching_good shape: {X_test_noisy_vector_stitching_good_34.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_expanded, X_test_noisy_random_expanded, X_test_expanded = transform_data(X_train, X_test_noisy_random, X_test)\n",
    "_, X_train_noisy_random_expanded, _ = transform_data(X_train, X_train_noisy_random, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare 90% clean and 10% distorted training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr shape: (100, 28, 28, 1), y_tr shape: (100,)\n",
      "X_tr_tda_34 shape: (100, 28, 28, 34), y_tr_tda_34 shape: (100,)\n",
      "X_tr_vector_stitching_34 shape: (100, 56, 28, 34), y_tr_vector_stitching_34 shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# prepare 90% clean and 10% noisy data for training and testing\n",
    "# X_tr_ should be clean raw data of 90% clean and 10% noisy\n",
    "\n",
    "percent = 10\n",
    "# calculate how many distorted data should be added to the clean data\n",
    "n = int((percent/100)*X_train_expanded.shape[0])\n",
    "\n",
    "\n",
    "X_tr = np.concatenate((X_train_expanded[:-n], X_train_noisy_random_expanded[:n]), axis=0)\n",
    "y_tr = np.concatenate((y_train[:-n], y_train[:n]), axis=0)\n",
    "X_tr, y_tr = shuffle(X_tr, y_tr, random_state=666)\n",
    "\n",
    "# the same for other data\n",
    "X_tr_tda_34 = np.concatenate((X_train_clean_tda_good_34[:-n], X_train_noisy_tda_good_34[:n]), axis=0)\n",
    "y_tr_tda_34 = np.concatenate((y_train[:-n], y_train[:n]), axis=0)\n",
    "X_tr_tda_34, y_tr_tda_34 = shuffle(X_tr_tda_34, y_tr_tda_34, random_state=666)\n",
    "\n",
    "\n",
    "X_tr_vector_stitching_34 = np.concatenate((X_train_clean_vector_stitching_good_34[:-n], X_train_noisy_vector_stitching_good_34[:n]), axis=0)\n",
    "y_tr_vector_stitching_34 = np.concatenate((y_train[:-n], y_train[:n]), axis=0)\n",
    "X_tr_vector_stitching_34, y_tr_vector_stitching_34 = shuffle(X_tr_vector_stitching_34, y_tr_vector_stitching_34, random_state=666)\n",
    "\n",
    "\n",
    "print(f\"X_tr shape: {X_tr.shape}, y_tr shape: {y_tr.shape}\")\n",
    "print(f\"X_tr_tda_34 shape: {X_tr_tda_34.shape}, y_tr_tda_34 shape: {y_tr_tda_34.shape}\")\n",
    "print(f\"X_tr_vector_stitching_34 shape: {X_tr_vector_stitching_34.shape}, y_tr_vector_stitching_34 shape: {y_tr_vector_stitching_34.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use new module to generate full experiment input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jawor\\Desktop\\Projekt_licencjacki\\data_preprocessing.py:42: FutureWarning: `seed` is a deprecated argument name for `random_noise`. It will be removed in version 0.23. Please use `rng` instead.\n",
      "  X_train_noisy = random_noise(X_train, mode=\"s&p\",amount=0.05, seed=666)\n",
      "c:\\Users\\jawor\\Desktop\\Projekt_licencjacki\\data_preprocessing.py:43: FutureWarning: `seed` is a deprecated argument name for `random_noise`. It will be removed in version 0.23. Please use `rng` instead.\n",
      "  X_test_noisy = random_noise(X_test, mode=\"s&p\",amount=0.05, seed=666)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1\n",
      "done2\n",
      "done3\n",
      "done4\n",
      "done5\n",
      "done6\n",
      "done7\n",
      "done8\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import process\n",
    "(X, y), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "data = process(data=(X, y), training_size=10, testing_size=10, dist_ratio=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "raw_model = Raw_Model() # cnn models working on raw images\n",
    "dummy_model = Dummy_Model() # fully dense model working on raw images\n",
    "tda_model_34 = TDA_PI34_Model() # cnn model working on persistance images\n",
    "tda_model_42 = TDA_PI42_Model() # cnn model working on persistance images\n",
    "vector_stitching_model_34 = VECTOR_STITCHING_PI_Model_34() # cnn model working on stitched raw and PI images\n",
    "vector_stitching_model_42 = VECTOR_STITCHING_PI_Model_42() # cnn model working on stitched raw and PI images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and validating models\n",
    "\n",
    "All models are trained on clean data, and then validated on only distorted data (look up 2nd paragraph to see plotted example images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 76ms/step - loss: 3.6559 - accuracy: 0.1000 - val_loss: 7.2002 - val_accuracy: 0.2000\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 3.1774 - accuracy: 0.2000 - val_loss: 7.0160 - val_accuracy: 0.1000\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 1.8087 - accuracy: 0.3000 - val_loss: 8.0114 - val_accuracy: 0.1000\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 1.6880 - accuracy: 0.4000 - val_loss: 6.3501 - val_accuracy: 0.1000\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 53ms/step - loss: 1.0204 - accuracy: 0.8000 - val_loss: 7.1780 - val_accuracy: 0.1000\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 49ms/step - loss: 0.7656 - accuracy: 0.8000 - val_loss: 8.4078 - val_accuracy: 0.1000\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 0.5464 - accuracy: 0.9000 - val_loss: 12.4109 - val_accuracy: 0.1000\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 51ms/step - loss: 0.1122 - accuracy: 1.0000 - val_loss: 13.5755 - val_accuracy: 0.1000\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.2312 - accuracy: 1.0000 - val_loss: 17.0702 - val_accuracy: 0.1000\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.1235 - accuracy: 1.0000 - val_loss: 16.0548 - val_accuracy: 0.1000\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.8420 - accuracy: 0.8000 - val_loss: 12.3465 - val_accuracy: 0.1000\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.5855 - accuracy: 0.8000 - val_loss: 16.4425 - val_accuracy: 0.1000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 45ms/step - loss: 0.5347 - accuracy: 0.8000 - val_loss: 16.1868 - val_accuracy: 0.1000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.2672 - accuracy: 0.9000 - val_loss: 20.2558 - val_accuracy: 0.1000\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.1706 - accuracy: 1.0000 - val_loss: 22.0438 - val_accuracy: 0.1000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 20.8822 - val_accuracy: 0.1000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 20.3682 - val_accuracy: 0.1000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 20.9798 - val_accuracy: 0.1000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 22.9880 - val_accuracy: 0.1000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 24.0088 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a8ceca2050>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TDA model\n",
    "\n",
    "tda_model_34.model.fit(data[\"X_tr_tda_34\"], data[\"y_tr_tda_34\"], epochs=20, batch_size=1, validation_data=(data[\"X_test_noisy_tda_good_34\"], data[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 1\n",
      "0 2\n",
      "0 4\n",
      "0 8\n",
      "0 0\n",
      "0 8\n",
      "0 7\n",
      "0 7\n",
      "0 4\n",
      "0 4\n",
      "0 2\n",
      "0 3\n",
      "0 6\n",
      "0 6\n",
      "0 7\n",
      "0 2\n",
      "0 0\n",
      "0 0\n",
      "0 7\n",
      "0 1\n",
      "0 6\n",
      "0 0\n",
      "0 5\n",
      "0 0\n",
      "0 4\n",
      "0 4\n",
      "0 3\n",
      "0 1\n",
      "0 3\n",
      "0 2\n",
      "0 6\n",
      "0 3\n",
      "0 0\n",
      "0 2\n",
      "0 3\n",
      "0 5\n",
      "0 8\n",
      "0 4\n",
      "0 1\n",
      "0 3\n",
      "0 9\n",
      "0 2\n",
      "0 3\n",
      "0 2\n",
      "0 6\n",
      "0 0\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 6\n",
      "0 5\n",
      "0 7\n",
      "0 5\n",
      "0 9\n",
      "0 7\n",
      "0 7\n",
      "0 2\n",
      "0 0\n",
      "0 9\n",
      "0 7\n",
      "0 2\n",
      "0 2\n",
      "0 9\n",
      "0 8\n",
      "0 7\n",
      "0 9\n",
      "0 4\n",
      "0 1\n",
      "0 0\n",
      "0 9\n",
      "0 8\n",
      "0 1\n",
      "0 9\n",
      "0 8\n",
      "0 1\n",
      "0 6\n",
      "0 5\n",
      "0 1\n",
      "0 9\n",
      "0 3\n",
      "0 3\n",
      "0 8\n",
      "0 3\n",
      "0 0\n",
      "0 1\n",
      "0 9\n",
      "0 8\n",
      "0 1\n",
      "0 5\n",
      "0 8\n",
      "0 6\n",
      "0 1\n",
      "0 7\n",
      "0 5\n",
      "0 9\n",
      "0 4\n",
      "0 8\n",
      "Accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "predictions_tda = tda_model_34.model.predict(X_test_noisy_tda_good_34)\n",
    "\n",
    "score =0\n",
    "for i,row in enumerate(predictions_tda):\n",
    "    print(np.argmax(row), y_test[i])\n",
    "    if np.argmax(row) == y_test[i]:\n",
    "        score += 1\n",
    "\n",
    "print(f\"Accuracy: {score/len(predictions_tda)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 3s 37ms/step - loss: 9.2035 - accuracy: 0.1800 - val_loss: 2.2980 - val_accuracy: 0.1800\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 23ms/step - loss: 1.9751 - accuracy: 0.4200 - val_loss: 2.2996 - val_accuracy: 0.1900\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 1.1975 - accuracy: 0.5800 - val_loss: 2.2990 - val_accuracy: 0.1200\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.8358 - accuracy: 0.7800 - val_loss: 2.2971 - val_accuracy: 0.2000\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 1s 32ms/step - loss: 0.7305 - accuracy: 0.7900 - val_loss: 2.2956 - val_accuracy: 0.2100\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.4406 - accuracy: 0.8600 - val_loss: 2.2954 - val_accuracy: 0.1900\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 1s 37ms/step - loss: 0.3232 - accuracy: 0.9100 - val_loss: 2.2938 - val_accuracy: 0.2100\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.3067 - accuracy: 0.9000 - val_loss: 2.2906 - val_accuracy: 0.2500\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 0s 22ms/step - loss: 0.2458 - accuracy: 0.9700 - val_loss: 2.2887 - val_accuracy: 0.2100\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.2987 - accuracy: 0.9000 - val_loss: 2.2873 - val_accuracy: 0.2300\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.3566 - accuracy: 0.9100 - val_loss: 2.2863 - val_accuracy: 0.2100\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.3214 - accuracy: 0.9100 - val_loss: 2.2865 - val_accuracy: 0.2100\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.2722 - accuracy: 0.9300 - val_loss: 2.2826 - val_accuracy: 0.2200\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2423 - accuracy: 0.9500 - val_loss: 2.2781 - val_accuracy: 0.2400\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 0s 24ms/step - loss: 0.2676 - accuracy: 0.9300 - val_loss: 2.2772 - val_accuracy: 0.2000\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.2449 - accuracy: 0.9400 - val_loss: 2.2748 - val_accuracy: 0.2100\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 1s 26ms/step - loss: 0.2272 - accuracy: 0.9500 - val_loss: 2.2737 - val_accuracy: 0.2000\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.2435 - accuracy: 0.9100 - val_loss: 2.2739 - val_accuracy: 0.2000\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 1s 27ms/step - loss: 0.3226 - accuracy: 0.8900 - val_loss: 2.2764 - val_accuracy: 0.1400\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 1s 28ms/step - loss: 0.3228 - accuracy: 0.9100 - val_loss: 2.2749 - val_accuracy: 0.2100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a8b97d0d30>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAW model\n",
    "raw_model.model.fit(X_tr, y_tr, epochs=20, batch_size=5, validation_data=(X_test_noisy_random_expanded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "1 1\n",
      "5 2\n",
      "1 4\n",
      "1 8\n",
      "5 0\n",
      "5 8\n",
      "1 7\n",
      "1 7\n",
      "1 4\n",
      "5 4\n",
      "1 2\n",
      "1 3\n",
      "5 6\n",
      "5 6\n",
      "5 7\n",
      "5 2\n",
      "5 0\n",
      "5 0\n",
      "1 7\n",
      "1 1\n",
      "1 6\n",
      "5 0\n",
      "5 5\n",
      "0 0\n",
      "5 4\n",
      "1 4\n",
      "5 3\n",
      "1 1\n",
      "5 3\n",
      "5 2\n",
      "1 6\n",
      "5 3\n",
      "5 0\n",
      "1 2\n",
      "5 3\n",
      "5 5\n",
      "5 8\n",
      "1 4\n",
      "1 1\n",
      "5 3\n",
      "5 9\n",
      "5 2\n",
      "5 3\n",
      "1 2\n",
      "5 6\n",
      "5 0\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "5 6\n",
      "5 5\n",
      "5 7\n",
      "5 5\n",
      "5 9\n",
      "1 7\n",
      "1 7\n",
      "1 2\n",
      "5 0\n",
      "1 9\n",
      "5 7\n",
      "5 2\n",
      "5 2\n",
      "5 9\n",
      "1 8\n",
      "1 7\n",
      "5 9\n",
      "5 4\n",
      "1 1\n",
      "5 0\n",
      "5 9\n",
      "1 8\n",
      "1 1\n",
      "5 9\n",
      "1 8\n",
      "1 1\n",
      "5 6\n",
      "5 5\n",
      "1 1\n",
      "5 9\n",
      "5 3\n",
      "5 3\n",
      "5 8\n",
      "5 3\n",
      "5 0\n",
      "1 1\n",
      "5 9\n",
      "5 8\n",
      "1 1\n",
      "5 5\n",
      "5 8\n",
      "5 6\n",
      "1 1\n",
      "5 7\n",
      "5 5\n",
      "5 9\n",
      "1 4\n",
      "1 8\n",
      "Accuracy: 0.21\n"
     ]
    }
   ],
   "source": [
    "predictions_raw = raw_model.model.predict(X_test_noisy_random_expanded)\n",
    "\n",
    "scoreraw=0\n",
    "\n",
    "for i,row in enumerate(predictions_raw):\n",
    "    print(np.argmax(row), y_test[i])\n",
    "    if np.argmax(row) == y_test[i]:\n",
    "        scoreraw += 1\n",
    "\n",
    "print(f\"Accuracy: {scoreraw/len(predictions_raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tda:  3     raw:  5     combined:  3     actual:  4\n",
      "tda:  5     raw:  5     combined:  5     actual:  5\n",
      "tda:  4     raw:  5     combined:  4     actual:  6\n",
      "tda:  3     raw:  1     combined:  3     actual:  1\n",
      "tda:  1     raw:  5     combined:  1     actual:  2\n",
      "tda:  1     raw:  1     combined:  1     actual:  4\n",
      "tda:  1     raw:  1     combined:  1     actual:  8\n",
      "tda:  0     raw:  5     combined:  0     actual:  0\n",
      "tda:  0     raw:  5     combined:  0     actual:  8\n",
      "tda:  1     raw:  1     combined:  1     actual:  7\n",
      "tda:  9     raw:  1     combined:  9     actual:  7\n",
      "tda:  5     raw:  1     combined:  5     actual:  4\n",
      "tda:  1     raw:  5     combined:  1     actual:  4\n",
      "tda:  1     raw:  1     combined:  1     actual:  2\n",
      "tda:  1     raw:  1     combined:  1     actual:  3\n",
      "tda:  6     raw:  5     combined:  6     actual:  6\n",
      "tda:  1     raw:  5     combined:  1     actual:  6\n",
      "tda:  1     raw:  5     combined:  1     actual:  7\n",
      "tda:  8     raw:  5     combined:  8     actual:  2\n",
      "tda:  8     raw:  5     combined:  0     actual:  0\n",
      "tda:  5     raw:  5     combined:  5     actual:  0\n",
      "tda:  9     raw:  1     combined:  9     actual:  7\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  1     raw:  1     combined:  1     actual:  6\n",
      "tda:  8     raw:  5     combined:  8     actual:  0\n",
      "tda:  1     raw:  5     combined:  5     actual:  5\n",
      "tda:  0     raw:  0     combined:  0     actual:  0\n",
      "tda:  3     raw:  5     combined:  3     actual:  4\n",
      "tda:  1     raw:  1     combined:  1     actual:  4\n",
      "tda:  1     raw:  5     combined:  1     actual:  3\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  1     raw:  5     combined:  1     actual:  3\n",
      "tda:  5     raw:  5     combined:  5     actual:  2\n",
      "tda:  1     raw:  1     combined:  1     actual:  6\n",
      "tda:  3     raw:  5     combined:  3     actual:  3\n",
      "tda:  7     raw:  5     combined:  1     actual:  0\n",
      "tda:  3     raw:  1     combined:  3     actual:  2\n",
      "tda:  1     raw:  5     combined:  1     actual:  3\n",
      "tda:  5     raw:  5     combined:  5     actual:  5\n",
      "tda:  1     raw:  5     combined:  1     actual:  8\n",
      "tda:  5     raw:  1     combined:  5     actual:  4\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  3     raw:  5     combined:  3     actual:  3\n",
      "tda:  1     raw:  5     combined:  1     actual:  9\n",
      "tda:  5     raw:  5     combined:  5     actual:  2\n",
      "tda:  5     raw:  5     combined:  5     actual:  3\n",
      "tda:  1     raw:  1     combined:  1     actual:  2\n",
      "tda:  1     raw:  5     combined:  1     actual:  6\n",
      "tda:  9     raw:  5     combined:  9     actual:  0\n",
      "tda:  1     raw:  5     combined:  1     actual:  4\n",
      "tda:  3     raw:  5     combined:  3     actual:  5\n",
      "tda:  4     raw:  5     combined:  5     actual:  6\n",
      "tda:  1     raw:  5     combined:  1     actual:  6\n",
      "tda:  5     raw:  5     combined:  5     actual:  5\n",
      "tda:  1     raw:  5     combined:  1     actual:  7\n",
      "tda:  1     raw:  5     combined:  1     actual:  5\n",
      "tda:  5     raw:  5     combined:  5     actual:  9\n",
      "tda:  1     raw:  1     combined:  1     actual:  7\n",
      "tda:  1     raw:  1     combined:  1     actual:  7\n",
      "tda:  0     raw:  1     combined:  0     actual:  2\n",
      "tda:  8     raw:  5     combined:  8     actual:  0\n",
      "tda:  1     raw:  1     combined:  1     actual:  9\n",
      "tda:  5     raw:  5     combined:  5     actual:  7\n",
      "tda:  0     raw:  5     combined:  0     actual:  2\n",
      "tda:  1     raw:  5     combined:  1     actual:  2\n",
      "tda:  1     raw:  5     combined:  1     actual:  9\n",
      "tda:  4     raw:  1     combined:  4     actual:  8\n",
      "tda:  1     raw:  1     combined:  1     actual:  7\n",
      "tda:  1     raw:  5     combined:  1     actual:  9\n",
      "tda:  4     raw:  5     combined:  4     actual:  4\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  0     raw:  5     combined:  0     actual:  0\n",
      "tda:  5     raw:  5     combined:  5     actual:  9\n",
      "tda:  1     raw:  1     combined:  1     actual:  8\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  5     raw:  5     combined:  5     actual:  9\n",
      "tda:  3     raw:  1     combined:  5     actual:  8\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  6     raw:  5     combined:  6     actual:  6\n",
      "tda:  5     raw:  5     combined:  5     actual:  5\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  1     raw:  5     combined:  1     actual:  9\n",
      "tda:  8     raw:  5     combined:  8     actual:  3\n",
      "tda:  7     raw:  5     combined:  7     actual:  3\n",
      "tda:  5     raw:  5     combined:  5     actual:  8\n",
      "tda:  1     raw:  5     combined:  1     actual:  3\n",
      "tda:  1     raw:  5     combined:  1     actual:  0\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  3     raw:  5     combined:  3     actual:  9\n",
      "tda:  8     raw:  5     combined:  8     actual:  8\n",
      "tda:  3     raw:  1     combined:  3     actual:  1\n",
      "tda:  1     raw:  5     combined:  1     actual:  5\n",
      "tda:  8     raw:  5     combined:  8     actual:  8\n",
      "tda:  6     raw:  5     combined:  6     actual:  6\n",
      "tda:  3     raw:  1     combined:  3     actual:  1\n",
      "tda:  5     raw:  5     combined:  5     actual:  7\n",
      "tda:  8     raw:  5     combined:  8     actual:  5\n",
      "tda:  9     raw:  5     combined:  9     actual:  9\n",
      "tda:  5     raw:  1     combined:  5     actual:  4\n",
      "tda:  1     raw:  1     combined:  1     actual:  8\n",
      "Combined Accuracy: 0.26\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "combined_score = 0\n",
    "for row_tda, row_raw in zip(predictions_tda, predictions_raw):\n",
    "    # multiply rows elementwise \n",
    "    combined = row_tda * row_raw\n",
    "    if np.argmax(combined) == y_test[i]:\n",
    "        combined_score += 1\n",
    "    print(\"tda: \",np.argmax(row_tda),\"    raw: \", np.argmax(row_raw), \"    combined: \", np.argmax(combined), \"    actual: \", y_test[i]) \n",
    "    i+=1\n",
    "\n",
    "print(f\"Combined Accuracy: {combined_score/len(predictions_tda)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 4s 45ms/step - loss: 2.6781 - accuracy: 0.2000 - val_loss: 2.4179 - val_accuracy: 0.1800\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 1s 34ms/step - loss: 2.2543 - accuracy: 0.2600 - val_loss: 2.1943 - val_accuracy: 0.1900\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 2.0302 - accuracy: 0.3100 - val_loss: 2.0727 - val_accuracy: 0.2700\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1.6966 - accuracy: 0.4000 - val_loss: 1.9657 - val_accuracy: 0.3900\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 1.3108 - accuracy: 0.5500 - val_loss: 2.0813 - val_accuracy: 0.3000\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 1.0625 - accuracy: 0.7000 - val_loss: 1.9380 - val_accuracy: 0.4000\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 1s 49ms/step - loss: 0.8620 - accuracy: 0.7500 - val_loss: 1.5820 - val_accuracy: 0.4500\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 1s 58ms/step - loss: 0.7205 - accuracy: 0.7500 - val_loss: 1.4694 - val_accuracy: 0.6000\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.4313 - accuracy: 0.8800 - val_loss: 1.4155 - val_accuracy: 0.5700\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.4201 - accuracy: 0.9100 - val_loss: 1.1865 - val_accuracy: 0.6100\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.2457 - accuracy: 0.9500 - val_loss: 1.1646 - val_accuracy: 0.6100\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 1s 31ms/step - loss: 0.2461 - accuracy: 0.9300 - val_loss: 1.0311 - val_accuracy: 0.7000\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 1s 35ms/step - loss: 0.2310 - accuracy: 0.9400 - val_loss: 1.1342 - val_accuracy: 0.6300\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.1014 - accuracy: 0.9800 - val_loss: 0.8939 - val_accuracy: 0.7400\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.0546 - accuracy: 0.9900 - val_loss: 0.9297 - val_accuracy: 0.7300\n",
      "Epoch 16/20\n",
      "20/20 [==============================] - 1s 30ms/step - loss: 0.1428 - accuracy: 0.9600 - val_loss: 0.8644 - val_accuracy: 0.7400\n",
      "Epoch 17/20\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.2485 - accuracy: 0.9500 - val_loss: 1.0077 - val_accuracy: 0.7100\n",
      "Epoch 18/20\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.1457 - accuracy: 0.9700 - val_loss: 0.9846 - val_accuracy: 0.7000\n",
      "Epoch 19/20\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.3200 - accuracy: 0.9700 - val_loss: 0.8616 - val_accuracy: 0.7100\n",
      "Epoch 20/20\n",
      "20/20 [==============================] - 1s 33ms/step - loss: 0.0909 - accuracy: 0.9700 - val_loss: 0.8447 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a8a4ed3730>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector stitching model\n",
    "\n",
    "vector_stitching_model_34.model.fit(X_tr_vector_stitching_34, y_tr_vector_stitching_34, epochs=20, batch_size=5, validation_data=(X_test_noisy_vector_stitching_good_34, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
