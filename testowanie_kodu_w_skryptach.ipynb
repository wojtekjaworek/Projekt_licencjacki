{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tda_models import TDA_PI34_Model, TDA_PI42_Model, VECTOR_STITCHING_PI_Model_34, VECTOR_STITCHING_PI_Model_42\n",
    "from models.raw_models import Raw_Model, Dummy_Model\n",
    "from models.combined_models import Combined_model\n",
    "from tda_pipelines import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch dataset, prepare training and testing sets, generate distorted sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jawor\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (70000, 784), y shape: (70000,)\n",
      "X_train shape: (1000, 28, 28), y_train shape: (1000,)\n",
      "X_test shape: (100, 28, 28), y_test shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "# fetch data, prepare for pipeline and test models\n",
    "\n",
    "from sklearn.datasets import fetch_openml \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "train_size, test_size = 1000, 100 # Reshape to (n_samples, n_pixels_x, n_pixels_y) \n",
    "X = X.reshape((-1, 28, 28)) \n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, train_size=train_size, test_size=test_size, stratify=y, random_state=666 ) \n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\") \n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "# mnist comes with string labels, we need to convert them to int\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jawor\\AppData\\Local\\Temp\\ipykernel_13676\\1520112787.py:5: FutureWarning: `seed` is a deprecated argument name for `random_noise`. It will be removed in version 0.23. Please use `rng` instead.\n",
      "  X_train_noisy = random_noise(X_train, mode=\"s&p\",amount=0.05, seed=666)\n",
      "C:\\Users\\jawor\\AppData\\Local\\Temp\\ipykernel_13676\\1520112787.py:6: FutureWarning: `seed` is a deprecated argument name for `random_noise`. It will be removed in version 0.23. Please use `rng` instead.\n",
      "  X_test_noisy = random_noise(X_test, mode=\"s&p\",amount=0.05, seed=666)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Noisy Image with Random Noise')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distort X_train and X_test a little bit not using giotto\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from skimage.util import random_noise\n",
    "X_train_noisy = random_noise(X_train, mode=\"s&p\",amount=0.05, seed=666)\n",
    "X_test_noisy = random_noise(X_test, mode=\"s&p\",amount=0.05, seed=666)\n",
    "\n",
    "# generate random noise matrix of size X_train_noisy.shape and X_test_noisy.shape but without original image\n",
    "\n",
    "X_train_noisy_random = np.random.rand(*X_train_noisy.shape)\n",
    "X_test_noisy_random = np.random.rand(*X_test_noisy.shape)\n",
    "\n",
    "# for each image in X_train_noisy and X_test_noisy, we will add the random noise matrix to the image\n",
    "\n",
    "X_train_noisy_random = X_train_noisy + X_train_noisy_random\n",
    "X_test_noisy_random = X_test_noisy + 0.5*X_test_noisy_random\n",
    "\n",
    "# plot the original image, the noisy image and the noisy image with random noise\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(X_test[5], cmap=\"gray\")\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[1].imshow(X_test_noisy[5], cmap=\"gray\")\n",
    "ax[1].set_title(\"Noisy Image\")\n",
    "ax[2].imshow(X_test_noisy_random[5], cmap=\"gray\")\n",
    "ax[2].set_title(\"Noisy Image with Random Noise\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TDA and Vector-stitching pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipelines \n",
    "\n",
    "tda_pipeline_34 = TDA_PI34_Pipeline()\n",
    "tda_pipeline_42 = TDA_PI42_Pipeline()\n",
    "vector_stitching_pipeline_34, tda_union_34 = VECTOR_STITCHING_PI_Pipeline_34()\n",
    "vector_stitching_pipeline_42, tda_union_42 = VECTOR_STITCHING_PI_Pipeline_42()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform raw data to persistance images and stitched RAW-PI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# clean data\n",
    "\n",
    "X_train_clean_tda_34 = tda_pipeline_34.fit_transform(X_train)\n",
    "print(\"done\")\n",
    "X_test_clean_tda_34 = tda_pipeline_34.transform(X_test)\n",
    "print(\"done\")\n",
    "X_train_clean_tda_42 = tda_pipeline_42.fit_transform(X_train)\n",
    "print(\"done\")\n",
    "X_test_clean_tda_42 = tda_pipeline_42.transform(X_test)\n",
    "print(\"done\")\n",
    "\n",
    "# distorted data\n",
    "X_train_noisy_tda_34 = tda_pipeline_34.fit_transform(X_train_noisy_random)\n",
    "print(\"done\")\n",
    "X_test_noisy_tda_34 = tda_pipeline_34.transform(X_test_noisy_random)\n",
    "print(\"done\")\n",
    "X_train_noisy_tda_42 = tda_pipeline_42.fit_transform(X_train_noisy_random)\n",
    "print(\"done\")\n",
    "X_test_noisy_tda_42 = tda_pipeline_42.transform(X_test_noisy_random)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#important for initializing Binarizer\n",
    "#X_training = tda_union.fit(X_train)\n",
    "\n",
    "#clean data\n",
    "X_train_clean_vector_stitching_34 = vector_stitching_pipeline_34.fit_transform(X_train)\n",
    "print(\"done\")\n",
    "X_test_clean_vector_stitching_34 = vector_stitching_pipeline_34.transform(X_test)\n",
    "print(\"done\")\n",
    "X_train_clean_vector_stitching_42 = vector_stitching_pipeline_42.fit_transform(X_train)\n",
    "print(\"done\")\n",
    "X_test_clean_vector_stitching_42 = vector_stitching_pipeline_42.transform(X_test)\n",
    "print(\"done\")\n",
    "\n",
    "# distorted data\n",
    "X_train_noisy_vector_stitching_34 = vector_stitching_pipeline_34.fit_transform(X_train_noisy_random)\n",
    "print(\"done\")\n",
    "X_test_noisy_vector_stitching_34 = vector_stitching_pipeline_34.transform(X_test_noisy_random)\n",
    "print(\"done\")\n",
    "X_train_noisy_vector_stitching_42 = vector_stitching_pipeline_42.fit_transform(X_train_noisy_random)\n",
    "print(\"done\")\n",
    "X_test_noisy_vector_stitching_42 = vector_stitching_pipeline_42.transform(X_test_noisy_random)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean_tda_good shape: (1000, 28, 28, 34), X_test_clean_tda_good shape: (100, 28, 28, 34)\n",
      "X_train_noisy_tda_good shape: (1000, 28, 28, 34), X_test_noisy_tda_good shape: (100, 28, 28, 34)\n",
      "X_train_clean_vector_stitching_good shape: (1000, 56, 28, 34), X_test_clean_vector_stitching_good shape: (100, 56, 28, 34)\n",
      "X_train_noisy_vector_stitching_good shape: (1000, 56, 28, 34), X_test_noisy_vector_stitching_good shape: (100, 56, 28, 34)\n",
      "X_train_clean_tda_good shape: (1000, 28, 28, 42), X_test_clean_tda_good shape: (100, 28, 28, 42)\n",
      "X_train_noisy_tda_good shape: (1000, 28, 28, 42), X_test_noisy_tda_good shape: (100, 28, 28, 42)\n",
      "X_train_clean_vector_stitching_good shape: (1000, 56, 28, 42), X_test_clean_vector_stitching_good shape: (100, 56, 28, 42)\n",
      "X_train_noisy_vector_stitching_good shape: (1000, 56, 28, 42), X_test_noisy_vector_stitching_good shape: (100, 56, 28, 42)\n"
     ]
    }
   ],
   "source": [
    "# this needs to be integrated into pipeline, transposing the data to fit the input shape of the model\n",
    "\n",
    "# normal tda\n",
    "X_train_clean_tda_good_34 = np.transpose(X_train_clean_tda_34, (0, 3, 2, 1))\n",
    "X_test_clean_tda_good_34 = np.transpose(X_test_clean_tda_34, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_tda_good_34 = np.transpose(X_train_noisy_tda_34, (0, 3, 2, 1))\n",
    "X_test_noisy_tda_good_34 = np.transpose(X_test_noisy_tda_34, (0, 3, 2, 1))\n",
    "\n",
    "X_train_clean_tda_good_42 = np.transpose(X_train_clean_tda_42, (0, 3, 2, 1))\n",
    "X_test_clean_tda_good_42 = np.transpose(X_test_clean_tda_42, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_tda_good_42 = np.transpose(X_train_noisy_tda_42, (0, 3, 2, 1))\n",
    "X_test_noisy_tda_good_42 = np.transpose(X_test_noisy_tda_42, (0, 3, 2, 1))\n",
    "\n",
    "#stitched\n",
    "\n",
    "X_train_clean_vector_stitching_good_34 = np.transpose(X_train_clean_vector_stitching_34, (0, 3, 2, 1))\n",
    "X_test_clean_vector_stitching_good_34 = np.transpose(X_test_clean_vector_stitching_34, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_vector_stitching_good_34 = np.transpose(X_train_noisy_vector_stitching_34, (0, 3, 2, 1))\n",
    "X_test_noisy_vector_stitching_good_34 = np.transpose(X_test_noisy_vector_stitching_34, (0, 3, 2, 1))\n",
    "\n",
    "X_train_clean_vector_stitching_good_42 = np.transpose(X_train_clean_vector_stitching_42, (0, 3, 2, 1))\n",
    "X_test_clean_vector_stitching_good_42 = np.transpose(X_test_clean_vector_stitching_42, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_vector_stitching_good_42 = np.transpose(X_train_noisy_vector_stitching_42, (0, 3, 2, 1))\n",
    "X_test_noisy_vector_stitching_good_42 = np.transpose(X_test_noisy_vector_stitching_42, (0, 3, 2, 1))\n",
    "\n",
    "# shapes\n",
    "print(f\"X_train_clean_tda_good shape: {X_train_clean_tda_good_34.shape}, X_test_clean_tda_good shape: {X_test_clean_tda_good_34.shape}\")\n",
    "print(f\"X_train_noisy_tda_good shape: {X_train_noisy_tda_good_34.shape}, X_test_noisy_tda_good shape: {X_test_noisy_tda_good_34.shape}\")\n",
    "print(f\"X_train_clean_vector_stitching_good shape: {X_train_clean_vector_stitching_good_34.shape}, X_test_clean_vector_stitching_good shape: {X_test_clean_vector_stitching_good_34.shape}\")\n",
    "print(f\"X_train_noisy_vector_stitching_good shape: {X_train_noisy_vector_stitching_good_34.shape}, X_test_noisy_vector_stitching_good shape: {X_test_noisy_vector_stitching_good_34.shape}\")\n",
    "\n",
    "print(f\"X_train_clean_tda_good shape: {X_train_clean_tda_good_42.shape}, X_test_clean_tda_good shape: {X_test_clean_tda_good_42.shape}\")\n",
    "print(f\"X_train_noisy_tda_good shape: {X_train_noisy_tda_good_42.shape}, X_test_noisy_tda_good shape: {X_test_noisy_tda_good_42.shape}\")\n",
    "print(f\"X_train_clean_vector_stitching_good shape: {X_train_clean_vector_stitching_good_42.shape}, X_test_clean_vector_stitching_good shape: {X_test_clean_vector_stitching_good_42.shape}\")\n",
    "print(f\"X_train_noisy_vector_stitching_good shape: {X_train_noisy_vector_stitching_good_42.shape}, X_test_noisy_vector_stitching_good shape: {X_test_noisy_vector_stitching_good_42.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_expanded, X_test_noisy_random_expanded, X_test_expanded = transform_data(X_train, X_test_noisy_random, X_test)\n",
    "_, X_train_noisy_random_expanded, _ = transform_data(X_train, X_train_noisy_random, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare 90% clean and 10% distorted training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# prepare 90% clean and 10% noisy data for training and testing\n",
    "# X_tr_ should be clean raw data of 90% clean and 10% noisy\n",
    "\n",
    "X_tr = np.concatenate((X_train_expanded, X_train_noisy_random_expanded[:100]), axis=0)\n",
    "y_tr = np.concatenate((y_train, y_train[:100]), axis=0)\n",
    "X_tr, y_tr = shuffle(X_tr, y_tr, random_state=666)\n",
    "\n",
    "# the same for other data\n",
    "X_tr_tda_34 = np.concatenate((X_train_clean_tda_good_34, X_train_noisy_tda_good_34[:100]), axis=0)\n",
    "y_tr_tda_34 = np.concatenate((y_train, y_train[:100]), axis=0)\n",
    "X_tr_tda_34, y_tr_tda_34 = shuffle(X_tr_tda_34, y_tr_tda_34, random_state=666)\n",
    "\n",
    "X_tr_tda_42 = np.concatenate((X_train_clean_tda_good_42, X_train_noisy_tda_good_42[:100]), axis=0)\n",
    "y_tr_tda_42 = np.concatenate((y_train, y_train[:100]), axis=0)\n",
    "X_tr_tda_42, y_tr_tda_42 = shuffle(X_tr_tda_42, y_tr_tda_42, random_state=666)\n",
    "\n",
    "X_tr_vector_stitching_34 = np.concatenate((X_train_clean_vector_stitching_good_34, X_train_noisy_vector_stitching_good_34[:100]), axis=0)\n",
    "y_tr_vector_stitching_34 = np.concatenate((y_train, y_train[:100]), axis=0)\n",
    "X_tr_vector_stitching_34, y_tr_vector_stitching_34 = shuffle(X_tr_vector_stitching_34, y_tr_vector_stitching_34, random_state=666)\n",
    "\n",
    "X_tr_vector_stitching_42 = np.concatenate((X_train_clean_vector_stitching_good_42, X_train_noisy_vector_stitching_good_42[:100]), axis=0)\n",
    "y_tr_vector_stitching_42 = np.concatenate((y_train, y_train[:100]), axis=0)\n",
    "X_tr_vector_stitching_42, y_tr_vector_stitching_42 = shuffle(X_tr_vector_stitching_42, y_tr_vector_stitching_42, random_state=666)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "raw_model = Raw_Model() # cnn models working on raw images\n",
    "dummy_model = Dummy_Model() # fully dense model working on raw images\n",
    "tda_model_34 = TDA_PI34_Model() # cnn model working on persistance images\n",
    "tda_model_42 = TDA_PI42_Model() # cnn model working on persistance images\n",
    "vector_stitching_model_34 = VECTOR_STITCHING_PI_Model_34() # cnn model working on stitched raw and PI images\n",
    "vector_stitching_model_42 = VECTOR_STITCHING_PI_Model_42() # cnn model working on stitched raw and PI images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and validating models\n",
    "\n",
    "All models are trained on clean data, and then validated on only distorted data (look up 2nd paragraph to see plotted example images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "220/220 [==============================] - 3s 8ms/step - loss: 1.5386 - accuracy: 0.5264 - val_loss: 1.8724 - val_accuracy: 0.3900\n",
      "Epoch 2/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.6933 - accuracy: 0.7791 - val_loss: 1.4947 - val_accuracy: 0.5700\n",
      "Epoch 3/20\n",
      "220/220 [==============================] - 1s 7ms/step - loss: 0.4995 - accuracy: 0.8573 - val_loss: 1.1396 - val_accuracy: 0.6100\n",
      "Epoch 4/20\n",
      "220/220 [==============================] - 2s 7ms/step - loss: 0.3922 - accuracy: 0.8764 - val_loss: 1.3780 - val_accuracy: 0.6100\n",
      "Epoch 5/20\n",
      "220/220 [==============================] - 1s 7ms/step - loss: 0.3069 - accuracy: 0.9055 - val_loss: 2.0568 - val_accuracy: 0.5700\n",
      "Epoch 6/20\n",
      "220/220 [==============================] - 2s 7ms/step - loss: 0.3156 - accuracy: 0.9073 - val_loss: 1.7080 - val_accuracy: 0.5200\n",
      "Epoch 7/20\n",
      "220/220 [==============================] - 1s 7ms/step - loss: 0.2480 - accuracy: 0.9236 - val_loss: 0.9925 - val_accuracy: 0.7100\n",
      "Epoch 8/20\n",
      "220/220 [==============================] - 1s 7ms/step - loss: 0.1528 - accuracy: 0.9536 - val_loss: 1.1121 - val_accuracy: 0.6800\n",
      "Epoch 9/20\n",
      "220/220 [==============================] - 2s 7ms/step - loss: 0.1540 - accuracy: 0.9536 - val_loss: 0.9923 - val_accuracy: 0.7400\n",
      "Epoch 10/20\n",
      "220/220 [==============================] - 2s 7ms/step - loss: 0.1575 - accuracy: 0.9409 - val_loss: 1.2289 - val_accuracy: 0.6500\n",
      "Epoch 11/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.2051 - accuracy: 0.9400 - val_loss: 1.2406 - val_accuracy: 0.7400\n",
      "Epoch 12/20\n",
      "220/220 [==============================] - 2s 7ms/step - loss: 0.1391 - accuracy: 0.9645 - val_loss: 1.4659 - val_accuracy: 0.7100\n",
      "Epoch 13/20\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.1026 - accuracy: 0.9718 - val_loss: 1.3219 - val_accuracy: 0.7400\n",
      "Epoch 14/20\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.1581 - accuracy: 0.9564 - val_loss: 1.7693 - val_accuracy: 0.6400\n",
      "Epoch 15/20\n",
      "220/220 [==============================] - 2s 10ms/step - loss: 0.1372 - accuracy: 0.9573 - val_loss: 2.1280 - val_accuracy: 0.5700\n",
      "Epoch 16/20\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.1370 - accuracy: 0.9582 - val_loss: 2.0782 - val_accuracy: 0.7000\n",
      "Epoch 17/20\n",
      "220/220 [==============================] - 2s 10ms/step - loss: 0.0522 - accuracy: 0.9873 - val_loss: 1.5824 - val_accuracy: 0.6900\n",
      "Epoch 18/20\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.0569 - accuracy: 0.9809 - val_loss: 1.4876 - val_accuracy: 0.7500\n",
      "Epoch 19/20\n",
      "220/220 [==============================] - 2s 10ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 1.7983 - val_accuracy: 0.6600\n",
      "Epoch 20/20\n",
      "220/220 [==============================] - 2s 8ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 2.0173 - val_accuracy: 0.7200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2211c93f6d0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TDA model\n",
    "\n",
    "tda_model_34.model.fit(X_tr_tda_34, y_tr_tda_34, epochs=20, batch_size=5, validation_data=(X_test_noisy_tda_good_34, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step\n",
      "9 9\n",
      "0 0\n",
      "3 3\n",
      "5 5\n",
      "7 7\n",
      "7 7\n",
      "4 4\n",
      "3 1\n",
      "1 1\n",
      "3 3\n",
      "7 7\n",
      "8 8\n",
      "1 8\n",
      "0 6\n",
      "2 2\n",
      "4 4\n",
      "6 6\n",
      "1 1\n",
      "0 0\n",
      "8 8\n",
      "6 6\n",
      "1 0\n",
      "1 1\n",
      "3 3\n",
      "0 0\n",
      "8 9\n",
      "9 4\n",
      "5 5\n",
      "4 4\n",
      "3 5\n",
      "0 0\n",
      "9 9\n",
      "5 3\n",
      "1 1\n",
      "2 3\n",
      "8 9\n",
      "0 0\n",
      "5 5\n",
      "0 0\n",
      "0 7\n",
      "2 2\n",
      "8 7\n",
      "8 9\n",
      "8 1\n",
      "3 3\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "2 1\n",
      "6 6\n",
      "4 4\n",
      "9 9\n",
      "3 3\n",
      "8 9\n",
      "1 8\n",
      "6 8\n",
      "4 4\n",
      "5 9\n",
      "1 8\n",
      "3 3\n",
      "7 7\n",
      "2 2\n",
      "8 1\n",
      "9 9\n",
      "0 0\n",
      "2 2\n",
      "5 5\n",
      "7 7\n",
      "8 8\n",
      "8 5\n",
      "0 0\n",
      "6 6\n",
      "1 1\n",
      "9 6\n",
      "4 4\n",
      "7 7\n",
      "0 0\n",
      "6 6\n",
      "9 9\n",
      "1 2\n",
      "2 2\n",
      "5 5\n",
      "1 1\n",
      "7 4\n",
      "6 6\n",
      "9 3\n",
      "6 6\n",
      "2 2\n",
      "6 8\n",
      "8 8\n",
      "4 4\n",
      "6 6\n",
      "2 2\n",
      "3 3\n",
      "8 8\n",
      "7 7\n",
      "7 7\n",
      "1 1\n",
      "8 4\n",
      "2 2\n",
      "Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "predictions_tda = tda_model_34.model.predict(X_test_noisy_tda_good_34)\n",
    "\n",
    "score =0\n",
    "for i,row in enumerate(predictions_tda):\n",
    "    print(np.argmax(row), y_test[i])\n",
    "    if np.argmax(row) == y_test[i]:\n",
    "        score += 1\n",
    "\n",
    "print(f\"Accuracy: {score/len(predictions_tda)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "110/110 [==============================] - 2s 12ms/step - loss: 1.9968 - accuracy: 0.3500 - val_loss: 2.0308 - val_accuracy: 0.2900\n",
      "Epoch 2/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 1.0926 - accuracy: 0.6509 - val_loss: 2.1448 - val_accuracy: 0.3200\n",
      "Epoch 3/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.7442 - accuracy: 0.7773 - val_loss: 1.6964 - val_accuracy: 0.3300\n",
      "Epoch 4/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.5696 - accuracy: 0.8409 - val_loss: 1.7817 - val_accuracy: 0.4300\n",
      "Epoch 5/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.4853 - accuracy: 0.8536 - val_loss: 1.2863 - val_accuracy: 0.5100\n",
      "Epoch 6/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.3765 - accuracy: 0.8964 - val_loss: 1.3745 - val_accuracy: 0.4900\n",
      "Epoch 7/20\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.3415 - accuracy: 0.8955 - val_loss: 1.8699 - val_accuracy: 0.4300\n",
      "Epoch 8/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.2943 - accuracy: 0.9045 - val_loss: 1.5486 - val_accuracy: 0.5300\n",
      "Epoch 9/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.2935 - accuracy: 0.9100 - val_loss: 1.7632 - val_accuracy: 0.4900\n",
      "Epoch 10/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.3482 - accuracy: 0.8927 - val_loss: 1.2449 - val_accuracy: 0.5500\n",
      "Epoch 11/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.2463 - accuracy: 0.9345 - val_loss: 1.7474 - val_accuracy: 0.5500\n",
      "Epoch 12/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1979 - accuracy: 0.9373 - val_loss: 1.4503 - val_accuracy: 0.5300\n",
      "Epoch 13/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1900 - accuracy: 0.9445 - val_loss: 1.3924 - val_accuracy: 0.5900\n",
      "Epoch 14/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1662 - accuracy: 0.9473 - val_loss: 1.8961 - val_accuracy: 0.5500\n",
      "Epoch 15/20\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1608 - accuracy: 0.9527 - val_loss: 1.6998 - val_accuracy: 0.5300\n",
      "Epoch 16/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1614 - accuracy: 0.9491 - val_loss: 1.2975 - val_accuracy: 0.7000\n",
      "Epoch 17/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1549 - accuracy: 0.9509 - val_loss: 1.5317 - val_accuracy: 0.6100\n",
      "Epoch 18/20\n",
      "110/110 [==============================] - 1s 9ms/step - loss: 0.1749 - accuracy: 0.9491 - val_loss: 2.0061 - val_accuracy: 0.5400\n",
      "Epoch 19/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.1330 - accuracy: 0.9600 - val_loss: 1.4685 - val_accuracy: 0.6900\n",
      "Epoch 20/20\n",
      "110/110 [==============================] - 1s 8ms/step - loss: 0.0649 - accuracy: 0.9773 - val_loss: 2.0534 - val_accuracy: 0.6200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2211c5f5a20>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tda_model_42.model.fit(X_tr_tda_42, y_tr_tda_42, epochs=20, batch_size=10, validation_data=(X_test_noisy_tda_good_42, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "220/220 [==============================] - 3s 6ms/step - loss: 3.2349 - accuracy: 0.4673 - val_loss: 2.2867 - val_accuracy: 0.3300\n",
      "Epoch 2/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.7652 - accuracy: 0.7445 - val_loss: 2.2631 - val_accuracy: 0.4800\n",
      "Epoch 3/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.5872 - accuracy: 0.8264 - val_loss: 2.2394 - val_accuracy: 0.4100\n",
      "Epoch 4/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.4304 - accuracy: 0.8682 - val_loss: 2.1836 - val_accuracy: 0.3600\n",
      "Epoch 5/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.3784 - accuracy: 0.8909 - val_loss: 2.1623 - val_accuracy: 0.3000\n",
      "Epoch 6/20\n",
      "220/220 [==============================] - 1s 7ms/step - loss: 0.3327 - accuracy: 0.9064 - val_loss: 2.1006 - val_accuracy: 0.3100\n",
      "Epoch 7/20\n",
      "220/220 [==============================] - 1s 7ms/step - loss: 0.3086 - accuracy: 0.9136 - val_loss: 2.0036 - val_accuracy: 0.6700\n",
      "Epoch 8/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.2918 - accuracy: 0.9291 - val_loss: 1.8717 - val_accuracy: 0.6400\n",
      "Epoch 9/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.3136 - accuracy: 0.9173 - val_loss: 1.7627 - val_accuracy: 0.5600\n",
      "Epoch 10/20\n",
      "220/220 [==============================] - 2s 8ms/step - loss: 0.3294 - accuracy: 0.9118 - val_loss: 1.3751 - val_accuracy: 0.6900\n",
      "Epoch 11/20\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.2929 - accuracy: 0.9227 - val_loss: 1.2642 - val_accuracy: 0.5300\n",
      "Epoch 12/20\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.2041 - accuracy: 0.9436 - val_loss: 1.0794 - val_accuracy: 0.6200\n",
      "Epoch 13/20\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.2460 - accuracy: 0.9327 - val_loss: 0.8777 - val_accuracy: 0.7200\n",
      "Epoch 14/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.1546 - accuracy: 0.9600 - val_loss: 0.9089 - val_accuracy: 0.6600\n",
      "Epoch 15/20\n",
      "220/220 [==============================] - 1s 5ms/step - loss: 0.0922 - accuracy: 0.9727 - val_loss: 0.6519 - val_accuracy: 0.7900\n",
      "Epoch 16/20\n",
      "220/220 [==============================] - 1s 5ms/step - loss: 0.1473 - accuracy: 0.9645 - val_loss: 0.6541 - val_accuracy: 0.7900\n",
      "Epoch 17/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.3150 - accuracy: 0.9418 - val_loss: 0.7414 - val_accuracy: 0.7100\n",
      "Epoch 18/20\n",
      "220/220 [==============================] - 1s 5ms/step - loss: 0.1386 - accuracy: 0.9636 - val_loss: 0.6325 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.0887 - accuracy: 0.9827 - val_loss: 0.5392 - val_accuracy: 0.8400\n",
      "Epoch 20/20\n",
      "220/220 [==============================] - 1s 5ms/step - loss: 0.1001 - accuracy: 0.9782 - val_loss: 0.6397 - val_accuracy: 0.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2211c5f5e10>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAW model\n",
    "raw_model.model.fit(X_tr, y_tr, epochs=20, batch_size=5, validation_data=(X_test_noisy_random_expanded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n",
      "7 9\n",
      "0 0\n",
      "3 3\n",
      "5 5\n",
      "7 7\n",
      "7 7\n",
      "4 4\n",
      "1 1\n",
      "1 1\n",
      "3 3\n",
      "7 7\n",
      "3 8\n",
      "8 8\n",
      "6 6\n",
      "2 2\n",
      "4 4\n",
      "6 6\n",
      "1 1\n",
      "0 0\n",
      "8 8\n",
      "6 6\n",
      "0 0\n",
      "1 1\n",
      "3 3\n",
      "5 0\n",
      "9 9\n",
      "8 4\n",
      "5 5\n",
      "4 4\n",
      "5 5\n",
      "0 0\n",
      "7 9\n",
      "3 3\n",
      "1 1\n",
      "3 3\n",
      "4 9\n",
      "0 0\n",
      "3 5\n",
      "0 0\n",
      "7 7\n",
      "2 2\n",
      "7 7\n",
      "9 9\n",
      "1 1\n",
      "3 3\n",
      "2 2\n",
      "5 5\n",
      "5 5\n",
      "1 1\n",
      "6 6\n",
      "9 4\n",
      "9 9\n",
      "3 3\n",
      "7 9\n",
      "8 8\n",
      "1 8\n",
      "4 4\n",
      "3 9\n",
      "1 8\n",
      "3 3\n",
      "7 7\n",
      "2 2\n",
      "1 1\n",
      "1 9\n",
      "0 0\n",
      "1 2\n",
      "7 5\n",
      "7 7\n",
      "8 8\n",
      "5 5\n",
      "0 0\n",
      "2 6\n",
      "1 1\n",
      "5 6\n",
      "4 4\n",
      "7 7\n",
      "0 0\n",
      "6 6\n",
      "9 9\n",
      "2 2\n",
      "2 2\n",
      "3 5\n",
      "1 1\n",
      "1 4\n",
      "6 6\n",
      "2 3\n",
      "8 6\n",
      "2 2\n",
      "8 8\n",
      "8 8\n",
      "4 4\n",
      "6 6\n",
      "2 2\n",
      "3 3\n",
      "8 8\n",
      "7 7\n",
      "7 7\n",
      "1 1\n",
      "1 4\n",
      "2 2\n",
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "predictions_raw = raw_model.model.predict(X_test_noisy_random_expanded)\n",
    "\n",
    "scoreraw=0\n",
    "\n",
    "for i,row in enumerate(predictions_raw):\n",
    "    print(np.argmax(row), y_test[i])\n",
    "    if np.argmax(row) == y_test[i]:\n",
    "        scoreraw += 1\n",
    "\n",
    "print(f\"Accuracy: {scoreraw/len(predictions_raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tda:  9     raw:  7     combined:  7     actual:  9\n",
      "tda:  0     raw:  0     combined:  0     actual:  0\n",
      "tda:  3     raw:  3     combined:  3     actual:  3\n",
      "tda:  5     raw:  5     combined:  5     actual:  5\n",
      "tda:  7     raw:  7     combined:  7     actual:  7\n",
      "tda:  7     raw:  7     combined:  7     actual:  7\n",
      "tda:  4     raw:  4     combined:  4     actual:  4\n",
      "tda:  3     raw:  1     combined:  1     actual:  1\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  3     raw:  3     combined:  3     actual:  3\n",
      "tda:  7     raw:  7     combined:  7     actual:  7\n",
      "tda:  8     raw:  3     combined:  8     actual:  8\n",
      "tda:  1     raw:  8     combined:  1     actual:  8\n",
      "tda:  0     raw:  6     combined:  6     actual:  6\n",
      "tda:  2     raw:  2     combined:  2     actual:  2\n",
      "tda:  4     raw:  4     combined:  4     actual:  4\n",
      "tda:  6     raw:  6     combined:  6     actual:  6\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  0     raw:  0     combined:  0     actual:  0\n",
      "tda:  8     raw:  8     combined:  8     actual:  8\n",
      "tda:  6     raw:  6     combined:  6     actual:  6\n",
      "tda:  1     raw:  0     combined:  0     actual:  0\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  3     raw:  3     combined:  3     actual:  3\n",
      "tda:  0     raw:  5     combined:  0     actual:  0\n",
      "tda:  8     raw:  9     combined:  8     actual:  9\n",
      "tda:  9     raw:  8     combined:  9     actual:  4\n",
      "tda:  5     raw:  5     combined:  5     actual:  5\n",
      "tda:  4     raw:  4     combined:  4     actual:  4\n",
      "tda:  3     raw:  5     combined:  5     actual:  5\n",
      "tda:  0     raw:  0     combined:  0     actual:  0\n",
      "tda:  9     raw:  7     combined:  9     actual:  9\n",
      "tda:  5     raw:  3     combined:  3     actual:  3\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  2     raw:  3     combined:  3     actual:  3\n",
      "tda:  8     raw:  4     combined:  8     actual:  9\n",
      "tda:  0     raw:  0     combined:  0     actual:  0\n",
      "tda:  5     raw:  3     combined:  5     actual:  5\n",
      "tda:  0     raw:  0     combined:  0     actual:  0\n",
      "tda:  0     raw:  7     combined:  0     actual:  7\n",
      "tda:  2     raw:  2     combined:  2     actual:  2\n",
      "tda:  8     raw:  7     combined:  8     actual:  7\n",
      "tda:  8     raw:  9     combined:  8     actual:  9\n",
      "tda:  8     raw:  1     combined:  8     actual:  1\n",
      "tda:  3     raw:  3     combined:  3     actual:  3\n",
      "tda:  2     raw:  2     combined:  2     actual:  2\n",
      "tda:  5     raw:  5     combined:  5     actual:  5\n",
      "tda:  5     raw:  5     combined:  5     actual:  5\n",
      "tda:  2     raw:  1     combined:  1     actual:  1\n",
      "tda:  6     raw:  6     combined:  6     actual:  6\n",
      "tda:  4     raw:  9     combined:  4     actual:  4\n",
      "tda:  9     raw:  9     combined:  9     actual:  9\n",
      "tda:  3     raw:  3     combined:  3     actual:  3\n",
      "tda:  8     raw:  7     combined:  7     actual:  9\n",
      "tda:  1     raw:  8     combined:  1     actual:  8\n",
      "tda:  6     raw:  1     combined:  2     actual:  8\n",
      "tda:  4     raw:  4     combined:  4     actual:  4\n",
      "tda:  5     raw:  3     combined:  5     actual:  9\n",
      "tda:  1     raw:  1     combined:  1     actual:  8\n",
      "tda:  3     raw:  3     combined:  3     actual:  3\n",
      "tda:  7     raw:  7     combined:  7     actual:  7\n",
      "tda:  2     raw:  2     combined:  2     actual:  2\n",
      "tda:  8     raw:  1     combined:  8     actual:  1\n",
      "tda:  9     raw:  1     combined:  9     actual:  9\n",
      "tda:  0     raw:  0     combined:  0     actual:  0\n",
      "tda:  2     raw:  1     combined:  2     actual:  2\n",
      "tda:  5     raw:  7     combined:  5     actual:  5\n",
      "tda:  7     raw:  7     combined:  7     actual:  7\n",
      "tda:  8     raw:  8     combined:  8     actual:  8\n",
      "tda:  8     raw:  5     combined:  5     actual:  5\n",
      "tda:  0     raw:  0     combined:  0     actual:  0\n",
      "tda:  6     raw:  2     combined:  6     actual:  6\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  9     raw:  5     combined:  5     actual:  6\n",
      "tda:  4     raw:  4     combined:  4     actual:  4\n",
      "tda:  7     raw:  7     combined:  7     actual:  7\n",
      "tda:  0     raw:  0     combined:  0     actual:  0\n",
      "tda:  6     raw:  6     combined:  6     actual:  6\n",
      "tda:  9     raw:  9     combined:  9     actual:  9\n",
      "tda:  1     raw:  2     combined:  1     actual:  2\n",
      "tda:  2     raw:  2     combined:  2     actual:  2\n",
      "tda:  5     raw:  3     combined:  5     actual:  5\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  7     raw:  1     combined:  1     actual:  4\n",
      "tda:  6     raw:  6     combined:  6     actual:  6\n",
      "tda:  9     raw:  2     combined:  3     actual:  3\n",
      "tda:  6     raw:  8     combined:  6     actual:  6\n",
      "tda:  2     raw:  2     combined:  2     actual:  2\n",
      "tda:  6     raw:  8     combined:  8     actual:  8\n",
      "tda:  8     raw:  8     combined:  8     actual:  8\n",
      "tda:  4     raw:  4     combined:  4     actual:  4\n",
      "tda:  6     raw:  6     combined:  6     actual:  6\n",
      "tda:  2     raw:  2     combined:  2     actual:  2\n",
      "tda:  3     raw:  3     combined:  3     actual:  3\n",
      "tda:  8     raw:  8     combined:  8     actual:  8\n",
      "tda:  7     raw:  7     combined:  7     actual:  7\n",
      "tda:  7     raw:  7     combined:  7     actual:  7\n",
      "tda:  1     raw:  1     combined:  1     actual:  1\n",
      "tda:  8     raw:  1     combined:  8     actual:  4\n",
      "tda:  2     raw:  2     combined:  2     actual:  2\n",
      "Combined Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "combined_score = 0\n",
    "for row_tda, row_raw in zip(predictions_tda, predictions_raw):\n",
    "    # multiply rows elementwise \n",
    "    combined = row_tda * row_raw\n",
    "    if np.argmax(combined) == y_test[i]:\n",
    "        combined_score += 1\n",
    "    print(\"tda: \",np.argmax(row_tda),\"    raw: \", np.argmax(row_raw), \"    combined: \", np.argmax(combined), \"    actual: \", y_test[i]) \n",
    "    i+=1\n",
    "\n",
    "print(f\"Combined Accuracy: {combined_score/len(predictions_tda)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "220/220 [==============================] - 4s 11ms/step - loss: 1.2930 - accuracy: 0.5845 - val_loss: 1.7986 - val_accuracy: 0.5800\n",
      "Epoch 2/20\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.5281 - accuracy: 0.8518 - val_loss: 0.9013 - val_accuracy: 0.7600\n",
      "Epoch 3/20\n",
      "220/220 [==============================] - 2s 8ms/step - loss: 0.3569 - accuracy: 0.8891 - val_loss: 1.0845 - val_accuracy: 0.7500\n",
      "Epoch 4/20\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.2412 - accuracy: 0.9336 - val_loss: 1.5040 - val_accuracy: 0.7400\n",
      "Epoch 5/20\n",
      "220/220 [==============================] - 2s 8ms/step - loss: 0.1857 - accuracy: 0.9391 - val_loss: 2.1928 - val_accuracy: 0.6700\n",
      "Epoch 6/20\n",
      "220/220 [==============================] - 2s 9ms/step - loss: 0.1928 - accuracy: 0.9436 - val_loss: 1.2407 - val_accuracy: 0.7700\n",
      "Epoch 7/20\n",
      "220/220 [==============================] - 2s 10ms/step - loss: 0.1523 - accuracy: 0.9527 - val_loss: 1.0901 - val_accuracy: 0.8100\n",
      "Epoch 8/20\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.0725 - accuracy: 0.9791 - val_loss: 1.3391 - val_accuracy: 0.8100\n",
      "Epoch 9/20\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.1325 - accuracy: 0.9564 - val_loss: 0.4342 - val_accuracy: 0.8900\n",
      "Epoch 10/20\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.1018 - accuracy: 0.9691 - val_loss: 0.5086 - val_accuracy: 0.8700\n",
      "Epoch 11/20\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.0758 - accuracy: 0.9782 - val_loss: 1.0951 - val_accuracy: 0.8600\n",
      "Epoch 12/20\n",
      "220/220 [==============================] - 3s 13ms/step - loss: 0.0706 - accuracy: 0.9773 - val_loss: 1.0631 - val_accuracy: 0.8300\n",
      "Epoch 13/20\n",
      "220/220 [==============================] - 4s 17ms/step - loss: 0.0394 - accuracy: 0.9882 - val_loss: 1.5682 - val_accuracy: 0.8100\n",
      "Epoch 14/20\n",
      "220/220 [==============================] - 3s 13ms/step - loss: 0.0697 - accuracy: 0.9809 - val_loss: 1.1507 - val_accuracy: 0.8600\n",
      "Epoch 15/20\n",
      "220/220 [==============================] - 3s 13ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 1.0454 - val_accuracy: 0.8700\n",
      "Epoch 16/20\n",
      "220/220 [==============================] - 3s 13ms/step - loss: 0.0490 - accuracy: 0.9818 - val_loss: 0.8157 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "220/220 [==============================] - 3s 13ms/step - loss: 0.1805 - accuracy: 0.9582 - val_loss: 0.9442 - val_accuracy: 0.8600\n",
      "Epoch 18/20\n",
      "220/220 [==============================] - 3s 14ms/step - loss: 0.0563 - accuracy: 0.9855 - val_loss: 0.7468 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "220/220 [==============================] - 3s 15ms/step - loss: 0.0854 - accuracy: 0.9700 - val_loss: 0.6171 - val_accuracy: 0.8700\n",
      "Epoch 20/20\n",
      "220/220 [==============================] - 3s 14ms/step - loss: 0.0672 - accuracy: 0.9827 - val_loss: 0.6804 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x221232d7190>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector stitching model\n",
    "\n",
    "vector_stitching_model_34.model.fit(X_tr_vector_stitching_34, y_tr_vector_stitching_34, epochs=20, batch_size=5, validation_data=(X_test_noisy_vector_stitching_good_34, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "110/110 [==============================] - 4s 22ms/step - loss: 1.6972 - accuracy: 0.4491 - val_loss: 1.7502 - val_accuracy: 0.5600\n",
      "Epoch 2/20\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 0.6391 - accuracy: 0.7991 - val_loss: 1.0982 - val_accuracy: 0.7400\n",
      "Epoch 3/20\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 0.4286 - accuracy: 0.8682 - val_loss: 1.1156 - val_accuracy: 0.7600\n",
      "Epoch 4/20\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 0.3387 - accuracy: 0.8982 - val_loss: 0.8829 - val_accuracy: 0.8100\n",
      "Epoch 5/20\n",
      "110/110 [==============================] - 2s 23ms/step - loss: 0.2116 - accuracy: 0.9245 - val_loss: 0.8066 - val_accuracy: 0.7800\n",
      "Epoch 6/20\n",
      "110/110 [==============================] - 2s 17ms/step - loss: 0.1489 - accuracy: 0.9527 - val_loss: 1.5682 - val_accuracy: 0.7500\n",
      "Epoch 7/20\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 0.1280 - accuracy: 0.9609 - val_loss: 0.9350 - val_accuracy: 0.8200\n",
      "Epoch 8/20\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 0.1066 - accuracy: 0.9636 - val_loss: 1.2570 - val_accuracy: 0.8000\n",
      "Epoch 9/20\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 0.0821 - accuracy: 0.9727 - val_loss: 1.9335 - val_accuracy: 0.7800\n",
      "Epoch 10/20\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 0.0809 - accuracy: 0.9764 - val_loss: 2.1856 - val_accuracy: 0.7100\n",
      "Epoch 11/20\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 0.0925 - accuracy: 0.9727 - val_loss: 1.1706 - val_accuracy: 0.8300\n",
      "Epoch 12/20\n",
      "110/110 [==============================] - 2s 17ms/step - loss: 0.0284 - accuracy: 0.9900 - val_loss: 1.5883 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 0.0505 - accuracy: 0.9809 - val_loss: 0.6025 - val_accuracy: 0.8200\n",
      "Epoch 14/20\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 0.0602 - accuracy: 0.9791 - val_loss: 0.7456 - val_accuracy: 0.8300\n",
      "Epoch 15/20\n",
      "110/110 [==============================] - 2s 19ms/step - loss: 0.0568 - accuracy: 0.9791 - val_loss: 1.9898 - val_accuracy: 0.7900\n",
      "Epoch 16/20\n",
      "110/110 [==============================] - 2s 18ms/step - loss: 0.0431 - accuracy: 0.9855 - val_loss: 1.6628 - val_accuracy: 0.8300\n",
      "Epoch 17/20\n",
      "110/110 [==============================] - 2s 22ms/step - loss: 0.0355 - accuracy: 0.9882 - val_loss: 1.4517 - val_accuracy: 0.8100\n",
      "Epoch 18/20\n",
      "110/110 [==============================] - 2s 20ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 1.2594 - val_accuracy: 0.8500\n",
      "Epoch 19/20\n",
      "110/110 [==============================] - 2s 17ms/step - loss: 0.0614 - accuracy: 0.9818 - val_loss: 0.5906 - val_accuracy: 0.8800\n",
      "Epoch 20/20\n",
      "110/110 [==============================] - 2s 21ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 1.0602 - val_accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22120dd7a60>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_stitching_model_42.model.fit(X_tr_vector_stitching_42, y_tr_vector_stitching_42, epochs=20, batch_size=10, validation_data=(X_test_noisy_vector_stitching_good_42, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
