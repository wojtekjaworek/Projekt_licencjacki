{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tda_models import TDA_PI34_Model, VECTOR_STITCHING_PI_Model\n",
    "from models.raw_models import Raw_Model, Dummy_Model\n",
    "from tda_pipelines import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch dataset, prepare training and testing sets, generate distorted sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (70000, 784), y shape: (70000,)\n",
      "X_train shape: (1000, 28, 28), y_train shape: (1000,)\n",
      "X_test shape: (300, 28, 28), y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# fetch data, prepare for pipeline and test models\n",
    "\n",
    "from sklearn.datasets import fetch_openml \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "train_size, test_size = 1000, 300 # Reshape to (n_samples, n_pixels_x, n_pixels_y) \n",
    "X = X.reshape((-1, 28, 28)) \n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, train_size=train_size, test_size=test_size, stratify=y, random_state=666 ) \n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\") \n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "# mnist comes with string labels, we need to convert them to int\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Noisy Image with Random Noise')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distort X_train and X_test a little bit not using giotto\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import random_noise\n",
    "X_train_noisy = random_noise(X_train, mode=\"s&p\",amount=0.05, seed=666)\n",
    "X_test_noisy = random_noise(X_test, mode=\"s&p\",amount=0.05, seed=666)\n",
    "\n",
    "# generate random noise matrix of size X_train_noisy.shape and X_test_noisy.shape but without original image\n",
    "\n",
    "X_train_noisy_random = np.random.rand(*X_train_noisy.shape)\n",
    "X_test_noisy_random = np.random.rand(*X_test_noisy.shape)\n",
    "\n",
    "# for each image in X_train_noisy and X_test_noisy, we will add the random noise matrix to the image\n",
    "\n",
    "X_train_noisy_random = X_train_noisy + X_train_noisy_random\n",
    "X_test_noisy_random = X_test_noisy + 0.5*X_test_noisy_random\n",
    "\n",
    "# plot the original image, the noisy image and the noisy image with random noise\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].imshow(X_test[5], cmap=\"gray\")\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[1].imshow(X_test_noisy[5], cmap=\"gray\")\n",
    "ax[1].set_title(\"Noisy Image\")\n",
    "ax[2].imshow(X_test_noisy_random[5], cmap=\"gray\")\n",
    "ax[2].set_title(\"Noisy Image with Random Noise\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load TDA and Vector-stitching pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipelines \n",
    "\n",
    "tda_pipeline = TDA_PI34_Pipeline()\n",
    "vector_stitching_pipeline, tda_union = VECTOR_STITCHING_PI_Pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform raw data to persistance images and stitched RAW-PI images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "\n",
    "X_train_clean_tda = tda_pipeline.fit_transform(X_train)\n",
    "X_test_clean_tda = tda_pipeline.transform(X_test)\n",
    "\n",
    "# distorted data\n",
    "X_train_noisy_tda = tda_pipeline.fit_transform(X_train_noisy_random)\n",
    "X_test_noisy_tda = tda_pipeline.transform(X_test_noisy_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 42, 28, 28)\n",
      "(300, 42, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_clean_tda.shape)\n",
    "print(X_test_clean_tda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#important for initializing Binarizer\n",
    "#X_training = tda_union.fit(X_train)\n",
    "\n",
    "#clean data\n",
    "X_train_clean_vector_stitching = vector_stitching_pipeline.fit_transform(X_train)\n",
    "X_test_clean_vector_stitching = vector_stitching_pipeline.transform(X_test)\n",
    "\n",
    "# distorted data\n",
    "X_train_noisy_vector_stitching = vector_stitching_pipeline.fit_transform(X_train_noisy_random)\n",
    "X_test_noisy_vector_stitching = vector_stitching_pipeline.transform(X_test_noisy_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_clean_tda_good shape: (1000, 28, 28, 42), X_test_clean_tda_good shape: (300, 28, 28, 42)\n",
      "X_train_noisy_tda_good shape: (1000, 28, 28, 42), X_test_noisy_tda_good shape: (300, 28, 28, 42)\n",
      "X_train_clean_vector_stitching_good shape: (1000, 56, 28, 42), X_test_clean_vector_stitching_good shape: (300, 56, 28, 42)\n",
      "X_train_noisy_vector_stitching_good shape: (1000, 56, 28, 42), X_test_noisy_vector_stitching_good shape: (300, 56, 28, 42)\n"
     ]
    }
   ],
   "source": [
    "# this needs to be integrated into pipeline, transposing the data to fit the input shape of the model\n",
    "\n",
    "# normal tda\n",
    "X_train_clean_tda_good = np.transpose(X_train_clean_tda, (0, 3, 2, 1))\n",
    "X_test_clean_tda_good = np.transpose(X_test_clean_tda, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_tda_good = np.transpose(X_train_noisy_tda, (0, 3, 2, 1))\n",
    "X_test_noisy_tda_good = np.transpose(X_test_noisy_tda, (0, 3, 2, 1))\n",
    "\n",
    "#stitched\n",
    "\n",
    "X_train_clean_vector_stitching_good = np.transpose(X_train_clean_vector_stitching, (0, 3, 2, 1))\n",
    "X_test_clean_vector_stitching_good = np.transpose(X_test_clean_vector_stitching, (0, 3, 2, 1))\n",
    "\n",
    "X_train_noisy_vector_stitching_good = np.transpose(X_train_noisy_vector_stitching, (0, 3, 2, 1))\n",
    "X_test_noisy_vector_stitching_good = np.transpose(X_test_noisy_vector_stitching, (0, 3, 2, 1))\n",
    "\n",
    "# shapes\n",
    "print(f\"X_train_clean_tda_good shape: {X_train_clean_tda_good.shape}, X_test_clean_tda_good shape: {X_test_clean_tda_good.shape}\")\n",
    "print(f\"X_train_noisy_tda_good shape: {X_train_noisy_tda_good.shape}, X_test_noisy_tda_good shape: {X_test_noisy_tda_good.shape}\")\n",
    "print(f\"X_train_clean_vector_stitching_good shape: {X_train_clean_vector_stitching_good.shape}, X_test_clean_vector_stitching_good shape: {X_test_clean_vector_stitching_good.shape}\")\n",
    "print(f\"X_train_noisy_vector_stitching_good shape: {X_train_noisy_vector_stitching_good.shape}, X_test_noisy_vector_stitching_good shape: {X_test_noisy_vector_stitching_good.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_expanded, X_test_noisy_random_expanded, X_test_expanded = transform_data(X_train, X_test_noisy_random, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "raw_model = Raw_Model() # cnn models working on raw images\n",
    "dummy_model = Dummy_Model() # fully dense model working on raw images\n",
    "tda_model = TDA_PI34_Model() # cnn model working on persistance images\n",
    "vector_stitching_model = VECTOR_STITCHING_PI_Model() # cnn model working on stitched raw and PI images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and validating models\n",
    "\n",
    "All models are trained on clean data, and then validated on only distorted data (look up 2nd paragraph to see plotted example images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.6816 - accuracy: 0.4590 - val_loss: 0.8896 - val_accuracy: 0.7233\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.7904 - accuracy: 0.7500 - val_loss: 0.4958 - val_accuracy: 0.8467\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.5103 - accuracy: 0.8470 - val_loss: 0.4770 - val_accuracy: 0.8500\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.3838 - accuracy: 0.8790 - val_loss: 0.5078 - val_accuracy: 0.8533\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.3015 - accuracy: 0.9070 - val_loss: 0.4208 - val_accuracy: 0.8700\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2363 - accuracy: 0.9290 - val_loss: 0.4196 - val_accuracy: 0.8900\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.2374 - accuracy: 0.9310 - val_loss: 0.3113 - val_accuracy: 0.9133\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1856 - accuracy: 0.9490 - val_loss: 0.5348 - val_accuracy: 0.8733\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1532 - accuracy: 0.9490 - val_loss: 0.4649 - val_accuracy: 0.8900\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1507 - accuracy: 0.9610 - val_loss: 0.6021 - val_accuracy: 0.8900\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1234 - accuracy: 0.9590 - val_loss: 0.3922 - val_accuracy: 0.9133\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1236 - accuracy: 0.9660 - val_loss: 0.4210 - val_accuracy: 0.9067\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1273 - accuracy: 0.9570 - val_loss: 0.4261 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.1376 - accuracy: 0.9650 - val_loss: 0.5216 - val_accuracy: 0.8833\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0790 - accuracy: 0.9720 - val_loss: 0.3167 - val_accuracy: 0.9367\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0845 - accuracy: 0.9800 - val_loss: 0.5078 - val_accuracy: 0.8933\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.1516 - accuracy: 0.9530 - val_loss: 0.4786 - val_accuracy: 0.9000\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0494 - accuracy: 0.9840 - val_loss: 0.4483 - val_accuracy: 0.9133\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0519 - accuracy: 0.9880 - val_loss: 0.4258 - val_accuracy: 0.9233\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 0.5531 - val_accuracy: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1819744ad60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TDA model\n",
    "\n",
    "tda_model.model.fit(X_train_clean_tda_good, y_train, epochs=20, batch_size=10, validation_data=(X_test_clean_tda_good, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 4.0743 - accuracy: 0.4960 - val_loss: 2.2943 - val_accuracy: 0.1433\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.6362 - accuracy: 0.8000 - val_loss: 2.2930 - val_accuracy: 0.1400\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8880 - val_loss: 2.2905 - val_accuracy: 0.1633\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.2185 - accuracy: 0.9300 - val_loss: 2.2838 - val_accuracy: 0.2567\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1886 - accuracy: 0.9310 - val_loss: 2.2880 - val_accuracy: 0.1900\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1005 - accuracy: 0.9590 - val_loss: 2.2793 - val_accuracy: 0.2300\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1058 - accuracy: 0.9650 - val_loss: 2.2854 - val_accuracy: 0.1433\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.1282 - accuracy: 0.9580 - val_loss: 2.2831 - val_accuracy: 0.3000\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.9550 - val_loss: 2.2806 - val_accuracy: 0.2067\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0768 - accuracy: 0.9730 - val_loss: 2.2809 - val_accuracy: 0.2800\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0754 - accuracy: 0.9750 - val_loss: 2.2840 - val_accuracy: 0.1900\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0253 - accuracy: 0.9930 - val_loss: 2.2774 - val_accuracy: 0.2567\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 2.2825 - val_accuracy: 0.2467\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0337 - accuracy: 0.9880 - val_loss: 2.2763 - val_accuracy: 0.2067\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9830 - val_loss: 2.2782 - val_accuracy: 0.1800\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0859 - accuracy: 0.9710 - val_loss: 2.2783 - val_accuracy: 0.1900\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0834 - accuracy: 0.9720 - val_loss: 2.2840 - val_accuracy: 0.1733\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9840 - val_loss: 2.2843 - val_accuracy: 0.1400\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 2.2797 - val_accuracy: 0.1667\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9910 - val_loss: 2.2755 - val_accuracy: 0.1633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x181975d94c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAW model\n",
    "raw_model.model.fit(X_train_expanded, y_train, epochs=20, batch_size=10, validation_data=(X_test_noisy_random_expanded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 1.3468 - accuracy: 0.5310 - val_loss: 0.3530 - val_accuracy: 0.9033\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.4944 - accuracy: 0.8450 - val_loss: 0.2505 - val_accuracy: 0.9300\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.3136 - accuracy: 0.9040 - val_loss: 0.1262 - val_accuracy: 0.9733\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.2183 - accuracy: 0.9340 - val_loss: 0.1308 - val_accuracy: 0.9667\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1648 - accuracy: 0.9480 - val_loss: 0.1276 - val_accuracy: 0.9567\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1283 - accuracy: 0.9540 - val_loss: 0.1545 - val_accuracy: 0.9667\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1303 - accuracy: 0.9540 - val_loss: 0.1716 - val_accuracy: 0.9467\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.1409 - accuracy: 0.9560 - val_loss: 0.1410 - val_accuracy: 0.9633\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.0557 - accuracy: 0.9840 - val_loss: 0.1285 - val_accuracy: 0.9567\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.0580 - accuracy: 0.9800 - val_loss: 0.1734 - val_accuracy: 0.9500\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.0629 - accuracy: 0.9810 - val_loss: 0.2090 - val_accuracy: 0.9567\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0664 - accuracy: 0.9770 - val_loss: 0.1433 - val_accuracy: 0.9700\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.0515 - accuracy: 0.9870 - val_loss: 0.1322 - val_accuracy: 0.9767\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0884 - accuracy: 0.9690 - val_loss: 0.1231 - val_accuracy: 0.9733\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0399 - accuracy: 0.9860 - val_loss: 0.1716 - val_accuracy: 0.9700\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 0.1002 - val_accuracy: 0.9600\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.0563 - accuracy: 0.9810 - val_loss: 0.0958 - val_accuracy: 0.9800\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0209 - accuracy: 0.9900 - val_loss: 0.1814 - val_accuracy: 0.9533\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0326 - accuracy: 0.9870 - val_loss: 0.1482 - val_accuracy: 0.9633\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.1570 - val_accuracy: 0.9633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18199da7160>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector stitching model\n",
    "\n",
    "vector_stitching_model.model.fit(X_train_clean_vector_stitching_good, y_train, epochs=20, batch_size=10, validation_data=(X_test_clean_vector_stitching_good, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
